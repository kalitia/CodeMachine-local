{
  "tasks": [
    {
      "id": "T1",
      "name": "Document system boundaries and planning assumptions",
      "phase": "Planning",
      "done": true,
      "acceptanceCriteria": "`docs/architecture/system-boundaries.md` captures scope, `.codemachine/plan.md` references the doc, and `docs/architecture/assumptions.md` logs new assumptions with timestamps.",
      "details": "### Purpose\nCapture authoritative system boundaries and assumptions so downstream agents share the same context.\n\n### Preconditions\n- Node.js >= <NODE_VERSION>\n- Repository cloned at <PROJECT_ROOT>\n- Latest specification available at `runner-prompts/user-input.md`\n\n### Artifacts To Create/Modify\n- `docs/architecture/system-boundaries.md`\n- `.codemachine/plan.md`\n- `docs/architecture/assumptions.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; sed -n '1,160p' runner-prompts/user-input.md\"` to refresh the requirement context.\n2. Create or update `docs/architecture/system-boundaries.md` using the template in subtask T1.1.\n3. Append a reference link under the \"Directory Structure\" or relevant section in `.codemachine/plan.md` via subtask T1.2.\n4. Log new/confirmed assumptions with timestamps in `docs/architecture/assumptions.md` via subtask T1.3.\n\n### Verification\n- `test -f docs/architecture/system-boundaries.md` exits 0.\n- `rg \"System Boundaries\" .codemachine/plan.md` returns at least one match.\n- `rg \"Assumption\" docs/architecture/assumptions.md` shows the newly logged entries.\n\n### Rollback\nRun `git restore docs/architecture/system-boundaries.md .codemachine/plan.md docs/architecture/assumptions.md`.\n\n### Variables\n- <PROJECT_ROOT>: Absolute repository path.\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T1.1",
          "name": "Author system boundaries summary",
          "details": "### Purpose\nCreate a living document summarizing in-scope and out-of-scope areas.\n\n### Preconditions\n- Specification reviewed (see Task T1 Purpose).\n\n### Artifacts To Create/Modify\n- `docs/architecture/system-boundaries.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > docs/architecture/system-boundaries.md\n# System Boundaries\n\n## In Scope\n- <IN_SCOPE_ITEMS>\n\n## Out of Scope\n- <OUT_OF_SCOPE_ITEMS>\n\n## External Integrations\n- <EXTERNAL_INTEGRATIONS>\n\n## Notes\n- Source: runner-prompts/user-input.md (synced on <SYNC_DATE>).\nEOF\"` to create/update the document.\n2. Run `bash -lc \"set -euo pipefail; git add docs/architecture/system-boundaries.md\"` to stage the file.\n\n### Verification\n- `rg \"In Scope\" docs/architecture/system-boundaries.md` returns entries.\n\n### Rollback\nRun `git restore --staged docs/architecture/system-boundaries.md` followed by `git checkout -- docs/architecture/system-boundaries.md`.\n\n### Variables\n- <IN_SCOPE_ITEMS>: Bullet list describing functionality to deliver.\n- <OUT_OF_SCOPE_ITEMS>: Bullet list of exclusions.\n- <EXTERNAL_INTEGRATIONS>: Bullet list of external systems.\n- <SYNC_DATE>: ISO 8601 date string when the spec was reviewed.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T1.2",
          "name": "Reference system boundaries in plan",
          "details": "### Purpose\nEnsure `.codemachine/plan.md` links to the new system boundaries doc for quick discovery.\n\n### Preconditions\n- Task T1.1 completed and staged.\n\n### Artifacts To Create/Modify\n- `.codemachine/plan.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; python3 - <<'PY'\nfrom pathlib import Path\nplan = Path('.codemachine/plan.md')\nneedle = '- [`System Boundaries`](docs/architecture/system-boundaries.md)'\ntext = plan.read_text()\nif needle not in text:\n    text = text.replace('## Directory Structure (with Phase Mapping)', '## Directory Structure (with Phase Mapping)\n- [`System Boundaries`](docs/architecture/system-boundaries.md) â€” Planning reference kept current by architects.\n')\n    plan.write_text(text)\nPY\"` to append an idempotent reference.\n2. Stage the change with `bash -lc \"set -euo pipefail; git add .codemachine/plan.md\"`.\n\n### Verification\n- `rg '\\[System Boundaries\\]' .codemachine/plan.md` shows the inserted link.\n\n### Rollback\nRun `git restore --staged .codemachine/plan.md` then `git checkout -- .codemachine/plan.md`.\n\n### Variables\n- <NO_PLACEHOLDERS>: This subtask does not require placeholders.\n",
          "blockedBy": [
            "T1.1"
          ],
          "canWorkInParallel": true
        },
        {
          "id": "T1.3",
          "name": "Log assumptions with timestamps",
          "details": "### Purpose\nMaintain an auditable list of planning assumptions.\n\n### Preconditions\n- Task T1.1 complete.\n\n### Artifacts To Create/Modify\n- `docs/architecture/assumptions.md`\n\n### Step-by-Step\n1. Ensure file exists by running `bash -lc \"set -euo pipefail; touch docs/architecture/assumptions.md\"`.\n2. Append new entries with `bash -lc \"set -euo pipefail; cat <<'EOF' >> docs/architecture/assumptions.md\n- <ASSUMPTION_TIMESTAMP>: <ASSUMPTION_TEXT>\nEOF\"`.\n3. Stage the update: `bash -lc \"set -euo pipefail; git add docs/architecture/assumptions.md\"`.\n\n### Verification\n- `tail -n 5 docs/architecture/assumptions.md` shows the new entry.\n\n### Rollback\nRun `git restore --staged docs/architecture/assumptions.md` then `git checkout -- docs/architecture/assumptions.md`.\n\n### Variables\n- <ASSUMPTION_TIMESTAMP>: ISO 8601 datetime (e.g., 2024-04-30T12:00Z).\n- <ASSUMPTION_TEXT>: Concise assumption statement.\n",
          "blockedBy": [
            "T1.1"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T1_TEST",
      "name": "Test Document system boundaries and planning assumptions",
      "phase": "Testing",
      "dependsOn": [
        "T1"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Document system boundaries and planning assumptions' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T1 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T1 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T1's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T1.\n\n### Rollback\nAddress deficiencies in Task T1 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T1.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T1_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T1.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T1_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T2",
      "name": "Automate repository validation workflows",
      "phase": "Planning",
      "done": true,
      "acceptanceCriteria": "Validation script exists in `scripts/ci/validate.sh`, npm `validate` script calls it, and `docs/architecture/README.md` documents the workflow.",
      "details": "### Purpose\nProvide deterministic validation so future agents can quickly verify scaffolding integrity.\n\n### Preconditions\n- Node.js >= <NODE_VERSION>\n- npm installed\n\n### Artifacts To Create/Modify\n- `scripts/ci/validate.sh`\n- `package.json`\n- `docs/architecture/README.md`\n\n### Step-by-Step\n1. Implement consolidated validation script via subtask T2.1.\n2. Wire npm `validate` script to call the new shell script via subtask T2.2.\n3. Document the workflow in architecture docs via subtask T2.3.\n\n### Verification\n- `bash -lc \"set -euo pipefail; scripts/ci/validate.sh\"` exits 0.\n- `jq -r '.scripts.validate' package.json` includes `scripts/ci/validate.sh`.\n- `rg 'validate.sh' docs/architecture/README.md` returns the doc entry.\n\n### Rollback\nRun `git restore scripts/ci/validate.sh package.json docs/architecture/README.md`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T2.1",
          "name": "Create consolidated validation script",
          "details": "### Purpose\nCentralize lint, type check, and test invocation.\n\n### Preconditions\n- `npm install` executed at least once.\n\n### Artifacts To Create/Modify\n- `scripts/ci/validate.sh`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > scripts/ci/validate.sh\n#!/usr/bin/env bash\nset -euo pipefail\n\nnpm run lint\nnpm run typecheck\nnpm run test -- --run\nEOF\"`.\n2. Run `bash -lc \"set -euo pipefail; chmod +x scripts/ci/validate.sh\"`.\n3. Stage the file `bash -lc \"set -euo pipefail; git add scripts/ci/validate.sh\"`.\n\n### Verification\n- `bash -lc \"set -euo pipefail; head -n 5 scripts/ci/validate.sh\"` shows shebang and commands.\n\n### Rollback\nRun `git restore --staged scripts/ci/validate.sh` then `git checkout -- scripts/ci/validate.sh`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T2.2",
          "name": "Update npm validate script",
          "details": "### Purpose\nEnsure `npm run validate` delegates to the shell script for consistency.\n\n### Preconditions\n- Subtask T2.1 completed.\n\n### Artifacts To Create/Modify\n- `package.json`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; node - <<'JS'\nconst fs = require('fs');\nconst pkg = JSON.parse(fs.readFileSync('package.json', 'utf8'));\npkg.scripts.validate = 'scripts/ci/validate.sh';\nfs.writeFileSync('package.json', JSON.stringify(pkg, null, 2) + '\\n');\nJS\"`.\n2. Stage the change with `bash -lc \"set -euo pipefail; git add package.json\"`.\n\n### Verification\n- `jq -r '.scripts.validate' package.json` outputs `scripts/ci/validate.sh`.\n\n### Rollback\nRun `git restore --staged package.json` then `git checkout -- package.json`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T2.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T2.3",
          "name": "Document validation workflow",
          "details": "### Purpose\nExplain validation expectations to collaborators.\n\n### Preconditions\n- Subtasks T2.1 and T2.2 complete.\n\n### Artifacts To Create/Modify\n- `docs/architecture/README.md`\n\n### Step-by-Step\n1. Append documentation with `bash -lc \"set -euo pipefail; cat <<'EOF' >> docs/architecture/README.md\n\n## Validation Workflow\n- Run `scripts/ci/validate.sh` before opening PRs to ensure lint, type check, and tests pass.\n- CI invokes the same script for consistency.\nEOF\"`.\n2. Stage the change `bash -lc \"set -euo pipefail; git add docs/architecture/README.md\"`.\n\n### Verification\n- `rg 'Validation Workflow' docs/architecture/README.md` returns the new section.\n\n### Rollback\nRun `git restore --staged docs/architecture/README.md` then `git checkout -- docs/architecture/README.md`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T2.1",
            "T2.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T2_TEST",
      "name": "Test Automate repository validation workflows",
      "phase": "Testing",
      "dependsOn": [
        "T2"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Automate repository validation workflows' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T2 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T2 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T2's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T2.\n\n### Rollback\nAddress deficiencies in Task T2 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T2.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T2_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T2.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T2_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T3",
      "name": "Define configuration schema and environment template",
      "phase": "Planning",
      "done": true,
      "acceptanceCriteria": "Environment schema lives in `src/config/schema/environment.schema.ts`, `.env.example` lists required variables, and docs explain configuration.",
      "details": "### Purpose\nLock down configuration contracts early to prevent runtime drift.\n\n### Preconditions\n- Node.js >= <NODE_VERSION>\n- TypeScript compiler configured (tsconfig present)\n\n### Artifacts To Create/Modify\n- `src/config/schema/environment.schema.ts`\n- `.env.example`\n- `docs/reference/environment.md`\n\n### Step-by-Step\n1. Implement Zod schema for environment variables via subtask T3.1.\n2. Generate `.env.example` aligned with schema via subtask T3.2.\n3. Document configuration usage via subtask T3.3.\n\n### Verification\n- `test -f src/config/schema/environment.schema.ts` exits 0.\n- `.env.example` includes all required keys from the schema.\n- `rg 'ENV' docs/reference/environment.md` shows guidance.\n\n### Rollback\nRun `git restore src/config/schema/environment.schema.ts .env.example docs/reference/environment.md`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T3.1",
          "name": "Implement environment Zod schema",
          "details": "### Purpose\nCreate a typed schema to validate environment variables at startup.\n\n### Preconditions\n- `npm install zod` already satisfied (see package.json).\n\n### Artifacts To Create/Modify\n- `src/config/schema/environment.schema.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/config/schema/environment.schema.ts\nimport { z } from 'zod';\n\nexport const environmentSchema = z.object({\n  NODE_ENV: z.enum(['development', 'test', 'production']).default('development'),\n  CODEX_HOME: z.string().min(1, 'CODEX_HOME must point to ~/.codemachine/codex'),\n  CODEMACHINE_MODE: z.enum(['build', 'template']).default('build'),\n  LOG_LEVEL: z.enum(['debug', 'info', 'warn', 'error']).default('info'),\n  TELEMETRY_ENABLED: z.coerce.boolean().default(false)\n});\n\nexport type EnvironmentConfig = z.infer<typeof environmentSchema>;\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/config/schema/environment.schema.ts\"`.\n\n### Verification\n- `rg 'environmentSchema' src/config/schema/environment.schema.ts` returns 1 match.\n\n### Rollback\nRun `git restore --staged src/config/schema/environment.schema.ts` then `git checkout -- src/config/schema/environment.schema.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T3.2",
          "name": "Create .env.example",
          "details": "### Purpose\nProvide developers with baseline environment configuration.\n\n### Preconditions\n- Subtask T3.1 complete.\n\n### Artifacts To Create/Modify\n- `.env.example`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > .env.example\nNODE_ENV=development\nCODEX_HOME=$HOME/.codemachine/codex\nCODEMACHINE_MODE=build\nLOG_LEVEL=info\nTELEMETRY_ENABLED=false\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add .env.example\"`.\n\n### Verification\n- `grep 'CODEX_HOME' .env.example` prints the variable.\n\n### Rollback\nRun `git restore --staged .env.example` then `git checkout -- .env.example`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T3.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T3.3",
          "name": "Document environment usage",
          "details": "### Purpose\nExplain configuration to contributors and operations teams.\n\n### Preconditions\n- Subtasks T3.1 and T3.2 complete.\n\n### Artifacts To Create/Modify\n- `docs/reference/environment.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > docs/reference/environment.md\n# Environment Configuration\n\n| Variable | Description | Phase | Required | Default |\n|----------|-------------|-------|----------|---------|\n| NODE_ENV | Node runtime mode | Runtime | Optional | development |\n| CODEX_HOME | Path to Codex credentials | Planning/Runtime | Required | ~/.codemachine/codex |\n| CODEMACHINE_MODE | CLI execution mode | Planning | Optional | build |\n| LOG_LEVEL | Logger threshold | Runtime | Optional | info |\n| TELEMETRY_ENABLED | Enable anonymized telemetry | Runtime | Optional | false |\n\nFollow `.env.example` to bootstrap local setups.\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add docs/reference/environment.md\"`.\n\n### Verification\n- `rg 'Environment Configuration' docs/reference/environment.md` returns the heading.\n\n### Rollback\nRun `git restore --staged docs/reference/environment.md` then `git checkout -- docs/reference/environment.md`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T3.1",
            "T3.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T3_TEST",
      "name": "Test Define configuration schema and environment template",
      "phase": "Testing",
      "dependsOn": [
        "T3"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Define configuration schema and environment template' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T3 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T3 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T3's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T3.\n\n### Rollback\nAddress deficiencies in Task T3 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T3.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T3_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T3.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T3_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T4",
      "name": "Design workflow blueprints and task templates",
      "phase": "Planning",
      "done": true,
      "acceptanceCriteria": "`docs/architecture/workflows.md` describes phase sequencing, `src/core/workflows/phase-map.ts` exports workflow metadata, and `src/core/tasks/task-blueprint.ts` provides reusable task template factories.",
      "details": "### Purpose\nCodify phase transitions and task blueprints so downstream automation remains consistent.\n\n### Preconditions\n- Planning tasks T1-T3 complete\n- Node.js >= <NODE_VERSION>\n\n### Artifacts To Create/Modify\n- `docs/architecture/workflows.md`\n- `src/core/workflows/phase-map.ts`\n- `src/core/tasks/task-blueprint.ts`\n\n### Step-by-Step\n1. Describe workflow diagrams in documentation (subtask T4.1).\n2. Implement phase map constants and helper functions (subtask T4.2).\n3. Provide task blueprint factory supporting four phases (subtask T4.3).\n\n### Verification\n- `rg 'Planning Phase Flow' docs/architecture/workflows.md` returns 1 match.\n- `rg 'phaseMap' src/core/workflows/phase-map.ts` returns 1 match.\n- `rg 'createTaskBlueprint' src/core/tasks/task-blueprint.ts` returns 1 match.\n\n### Rollback\nRun `git restore docs/architecture/workflows.md src/core/workflows/phase-map.ts src/core/tasks/task-blueprint.ts`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T4.1",
          "name": "Draft workflow documentation",
          "details": "### Purpose\nExplain Planningâ†’Buildingâ†’Testingâ†’Runtime orchestration for contributors.\n\n### Preconditions\n- Tasks T1-T3 complete.\n\n### Artifacts To Create/Modify\n- `docs/architecture/workflows.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > docs/architecture/workflows.md\n# Workflow Blueprint\n\n## Planning Phase Flow\n1. <PLANNING_STEP_ONE>\n2. <PLANNING_STEP_TWO>\n\n## Building Phase Flow\n1. <BUILDING_STEP_ONE>\n2. <BUILDING_STEP_TWO>\n\n## Testing Phase Flow\n1. <TESTING_STEP_ONE>\n2. <TESTING_STEP_TWO>\n\n## Runtime Phase Flow\n1. <RUNTIME_STEP_ONE>\n2. <RUNTIME_STEP_TWO>\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add docs/architecture/workflows.md\"`.\n\n### Verification\n- `rg 'Workflow Blueprint' docs/architecture/workflows.md` returns the heading.\n\n### Rollback\nRun `git restore --staged docs/architecture/workflows.md` then `git checkout -- docs/architecture/workflows.md`.\n\n### Variables\n- <PLANNING_STEP_ONE>: First planning action.\n- <PLANNING_STEP_TWO>: Second planning action.\n- <BUILDING_STEP_ONE>: First building action.\n- <BUILDING_STEP_TWO>: Second building action.\n- <TESTING_STEP_ONE>: First testing action.\n- <TESTING_STEP_TWO>: Second testing action.\n- <RUNTIME_STEP_ONE>: First runtime action.\n- <RUNTIME_STEP_TWO>: Second runtime action.\n",
          "blockedBy": [
            "T1_TEST",
            "T2_TEST",
            "T3_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T4.2",
          "name": "Implement phase map constants",
          "details": "### Purpose\nProvide programmatic representation of phase sequencing.\n\n### Preconditions\n- Subtask T4.1 complete.\n\n### Artifacts To Create/Modify\n- `src/core/workflows/phase-map.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/core/workflows/phase-map.ts\nexport type Phase = 'Planning' | 'Building' | 'Testing' | 'Runtime';\n\nexport interface PhaseDefinition {\n  id: Phase;\n  description: string;\n  next: Phase | null;\n}\n\nexport const phaseMap: Record<Phase, PhaseDefinition> = {\n  Planning: {\n    id: 'Planning',\n    description: '<PLANNING_DESCRIPTION>',\n    next: 'Building'\n  },\n  Building: {\n    id: 'Building',\n    description: '<BUILDING_DESCRIPTION>',\n    next: 'Testing'\n  },\n  Testing: {\n    id: 'Testing',\n    description: '<TESTING_DESCRIPTION>',\n    next: 'Runtime'\n  },\n  Runtime: {\n    id: 'Runtime',\n    description: '<RUNTIME_DESCRIPTION>',\n    next: null\n  }\n};\n\nexport function getNextPhase(phase: Phase): Phase | null {\n  return phaseMap[phase].next;\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/core/workflows/phase-map.ts\"`.\n\n### Verification\n- `tsc --noEmit src/core/workflows/phase-map.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/core/workflows/phase-map.ts` then `git checkout -- src/core/workflows/phase-map.ts`.\n\n### Variables\n- <PLANNING_DESCRIPTION>: Text summarizing planning outcomes.\n- <BUILDING_DESCRIPTION>: Text summarizing building outcomes.\n- <TESTING_DESCRIPTION>: Text summarizing testing outcomes.\n- <RUNTIME_DESCRIPTION>: Text summarizing runtime outcomes.\n",
          "blockedBy": [
            "T4.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T4.3",
          "name": "Create task blueprint factory",
          "details": "### Purpose\nGenerate normalized task objects for `tasks.json` updates.\n\n### Preconditions\n- Subtask T4.2 complete.\n\n### Artifacts To Create/Modify\n- `src/core/tasks/task-blueprint.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/core/tasks/task-blueprint.ts\nimport { z } from 'zod';\nimport { phaseMap, type Phase } from '../workflows/phase-map.js';\n\nconst blueprintSchema = z.object({\n  id: z.string(),\n  name: z.string(),\n  phase: z.custom<Phase>(),\n  description: z.string(),\n  acceptanceCriteria: z.string()\n});\n\nexport type TaskBlueprint = z.infer<typeof blueprintSchema>;\n\nexport function createTaskBlueprint(input: TaskBlueprint): TaskBlueprint {\n  blueprintSchema.parse(input);\n  if (!phaseMap[input.phase]) {\n    throw new Error(`Unknown phase ${input.phase}`);\n  }\n  return input;\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/core/tasks/task-blueprint.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/core/tasks/task-blueprint.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/core/tasks/task-blueprint.ts` then `git checkout -- src/core/tasks/task-blueprint.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T4.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T4_TEST",
      "name": "Test Design workflow blueprints and task templates",
      "phase": "Testing",
      "dependsOn": [
        "T4"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Design workflow blueprints and task templates' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T4 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T4 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T4's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T4.\n\n### Rollback\nAddress deficiencies in Task T4 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T4.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T4_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T4.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T4_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T5",
      "name": "Implement CLI entrypoint and command router",
      "phase": "Building",
      "done": true,
      "dependsOn": [
        "T4_TEST"
      ],
      "acceptanceCriteria": "`src/app/index.ts` boots Commander with global options, `src/cli/commands/register-cli.ts` registers base commands, and unit tests cover registration behaviour.",
      "details": "### Purpose\nDeliver a functional CLI entrypoint that orchestrates command registration.\n\n### Preconditions\n- Planning artifacts T1-T4 complete\n- Node.js >= <NODE_VERSION>\n\n### Artifacts To Create/Modify\n- `src/app/index.ts`\n- `src/cli/commands/register-cli.ts`\n- `tests/unit/cli/register-cli.spec.ts`\n\n### Step-by-Step\n1. Implement `runCodemachineCli` entrypoint logic (subtask T5.1).\n2. Flesh out `registerCli` with command scaffolding (subtask T5.2).\n3. Add unit tests ensuring command registration (subtask T5.3).\n\n### Verification\n- `npm run typecheck -- src/app/index.ts src/cli/commands/register-cli.ts` exits 0.\n- `npm run test -- tests/unit/cli/register-cli.spec.ts` exits 0.\n- `node dist/index.js --help` (after build) lists expected commands.\n\n### Rollback\nRun `git restore src/app/index.ts src/cli/commands/register-cli.ts tests/unit/cli/register-cli.spec.ts`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T5.1",
          "name": "Enhance CLI entrypoint",
          "details": "### Purpose\nEnsure the CLI boots Commander with lifecycle hooks.\n\n### Preconditions\n- Existing `src/app/index.ts` present.\n\n### Artifacts To Create/Modify\n- `src/app/index.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/app/index.ts\nimport { Command } from 'commander';\nimport { registerCli } from '../cli/commands/register-cli.js';\n\nexport async function runCodemachineCli(argv: string[] = process.argv): Promise<void> {\n  const program = new Command();\n  program\n    .name('codemachine')\n    .description('Codemachine multi-agent CLI orchestrator')\n    .option('-d, --dir <path>', 'Working directory override', process.cwd())\n    .hook('preAction', () => {\n      // <PRE_ACTION_HOOKS>\n    });\n\n  registerCli(program);\n  await program.parseAsync(argv);\n}\n\nif (process.argv[1] && process.argv[1].includes('index')) {\n  runCodemachineCli().catch((error) => {\n    console.error(error);\n    process.exitCode = 1;\n  });\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/app/index.ts\"`.\n\n### Verification\n- `rg 'runCodemachineCli' src/app/index.ts` returns the function.\n\n### Rollback\nRun `git restore --staged src/app/index.ts` then `git checkout -- src/app/index.ts`.\n\n### Variables\n- <PRE_ACTION_HOOKS>: Placeholder for telemetry/bootstrap logic.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T5.2",
          "name": "Implement registerCli scaffolding",
          "details": "### Purpose\nExpose `/start`, `/templates`, `/login`, `/logout`, `/version`, `/help`, `/mcp` commands.\n\n### Preconditions\n- Subtask T5.1 staged.\n\n### Artifacts To Create/Modify\n- `src/cli/commands/register-cli.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/cli/commands/register-cli.ts\nimport { Command } from 'commander';\nimport { registerStartCommand } from './start.command.js';\nimport { registerTemplatesCommand } from './templates.command.js';\nimport { registerAuthCommands } from './auth.command.js';\n\nexport function registerCli(program: Command): void {\n  registerStartCommand(program);\n  registerTemplatesCommand(program);\n  registerAuthCommands(program);\n\n  program\n    .command('version')\n    .description('Display CLI version')\n    .action(async () => {\n      const pkg = await import('../../../package.json', { assert: { type: 'json' } });\n      console.log(`CodeMachine v${pkg.default.version}`);\n    });\n\n  program\n    .command('mcp')\n    .description('Model Context Protocol utilities (coming soon)')\n    .action(() => {\n      console.log('<MCP_PLACEHOLDER>');\n    });\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/cli/commands/register-cli.ts\"`.\n\n### Verification\n- `rg 'registerStartCommand' src/cli/commands/register-cli.ts` returns 1 match.\n\n### Rollback\nRun `git restore --staged src/cli/commands/register-cli.ts` then `git checkout -- src/cli/commands/register-cli.ts`.\n\n### Variables\n- <MCP_PLACEHOLDER>: Temporary output message until feature ships.\n",
          "blockedBy": [
            "T5.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T5.3",
          "name": "Add unit tests for command registration",
          "details": "### Purpose\nProtect CLI command wiring with automated tests.\n\n### Preconditions\n- Subtasks T5.1 and T5.2 complete.\n\n### Artifacts To Create/Modify\n- `tests/unit/cli/register-cli.spec.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; mkdir -p tests/unit/cli\"`.\n2. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > tests/unit/cli/register-cli.spec.ts\nimport { Command } from 'commander';\nimport { registerCli } from '../../../src/cli/commands/register-cli.js';\n\ndescribe('registerCli', () => {\n  it('registers base commands', async () => {\n    const program = new Command();\n    registerCli(program);\n    const commands = program.commands.map((cmd) => cmd.name());\n    expect(commands).toEqual(expect.arrayContaining(<EXPECTED_COMMANDS>));\n  });\n});\nEOF\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add tests/unit/cli/register-cli.spec.ts\"`.\n\n### Verification\n- `npm run test -- tests/unit/cli/register-cli.spec.ts` exits 0.\n\n### Rollback\nRun `git restore --staged tests/unit/cli/register-cli.spec.ts` then `git checkout -- tests/unit/cli/register-cli.spec.ts`.\n\n### Variables\n- <EXPECTED_COMMANDS>: Array of expected command names (e.g., ['start','templates','login','logout','version','mcp']).\n",
          "blockedBy": [
            "T5.1",
            "T5.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T5_TEST",
      "name": "Test Implement CLI entrypoint and command router",
      "phase": "Testing",
      "dependsOn": [
        "T5"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Implement CLI entrypoint and command router' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T5 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T5 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T5's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T5.\n\n### Rollback\nAddress deficiencies in Task T5 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T5.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T5_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T5.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T5_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T6",
      "name": "Create /start command and planning handshake",
      "phase": "Building",
      "done": true,
      "dependsOn": [
        "T5_TEST"
      ],
      "acceptanceCriteria": "`src/cli/commands/start.command.ts` orchestrates planning prompts, `src/core/workflows/planning-workflow.ts` encapsulates logic, and integration test covers handshake.",
      "details": "### Purpose\nDeliver the primary `/start` command that validates specification readiness and kicks off Planning phase workflows.\n\n### Preconditions\n- Task T5 finished\n- Node.js >= <NODE_VERSION>\n\n### Artifacts To Create/Modify\n- `src/cli/commands/start.command.ts`\n- `src/core/workflows/planning-workflow.ts`\n- `tests/integration/workflows/planning-workflow.spec.ts`\n\n### Step-by-Step\n1. Implement CLI command wrapper (subtask T6.1).\n2. Build planning workflow module (subtask T6.2).\n3. Add integration test (subtask T6.3).\n\n### Verification\n- `npm run typecheck -- src/cli/commands/start.command.ts src/core/workflows/planning-workflow.ts` exits 0.\n- `npm run test -- tests/integration/workflows/planning-workflow.spec.ts` exits 0.\n\n### Rollback\nRun `git restore src/cli/commands/start.command.ts src/core/workflows/planning-workflow.ts tests/integration/workflows/planning-workflow.spec.ts`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T6.1",
          "name": "Implement start command",
          "details": "### Purpose\nGuide user through specification confirmation and workflow kickoff.\n\n### Preconditions\n- Task T5 complete.\n\n### Artifacts To Create/Modify\n- `src/cli/commands/start.command.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/cli/commands/start.command.ts\nimport { Command } from 'commander';\nimport { runPlanningWorkflow } from '../../core/workflows/planning-workflow.js';\n\nexport function registerStartCommand(program: Command): void {\n  program\n    .command('start')\n    .description('Start project generation workflow')\n    .option('--force', 'Skip specification confirmation prompt', false)\n    .action(async (options) => {\n      await runPlanningWorkflow({\n        force: options.force,\n        specificationPath: '<SPEC_PATH>'\n      });\n    });\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/cli/commands/start.command.ts\"`.\n\n### Verification\n- `rg 'registerStartCommand' src/cli/commands/start.command.ts` returns implementation.\n\n### Rollback\nRun `git restore --staged src/cli/commands/start.command.ts` then `git checkout -- src/cli/commands/start.command.ts`.\n\n### Variables\n- <SPEC_PATH>: Default specification path (e.g., `.codemachine/inputs/specifications.md`).\n",
          "blockedBy": [
            "T5_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T6.2",
          "name": "Build planning workflow module",
          "details": "### Purpose\nEncapsulate specification confirmation and task generation steps.\n\n### Preconditions\n- Subtask T6.1 staged.\n\n### Artifacts To Create/Modify\n- `src/core/workflows/planning-workflow.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/core/workflows/planning-workflow.ts\nimport { promises as fs } from 'fs';\nimport { phaseMap } from './phase-map.js';\n\ninterface PlanningWorkflowOptions {\n  force: boolean;\n  specificationPath: string;\n}\n\nexport async function runPlanningWorkflow(options: PlanningWorkflowOptions): Promise<void> {\n  const { force, specificationPath } = options;\n  if (!force) {\n    const spec = await fs.readFile(specificationPath, 'utf8');\n    if (!spec.trim()) {\n      throw new Error('Specification file is empty.');\n    }\n  }\n  // <TASK_GRAPH_GENERATION>\n  console.log('Planning workflow complete, next phase:', phaseMap.Planning.next);\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/core/workflows/planning-workflow.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/core/workflows/planning-workflow.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/core/workflows/planning-workflow.ts` then `git checkout -- src/core/workflows/planning-workflow.ts`.\n\n### Variables\n- <TASK_GRAPH_GENERATION>: Placeholder invoking task blueprint builder.\n",
          "blockedBy": [
            "T6.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T6.3",
          "name": "Add planning workflow integration test",
          "details": "### Purpose\nValidate CLI command and workflow interaction end-to-end.\n\n### Preconditions\n- Subtasks T6.1 and T6.2 complete.\n\n### Artifacts To Create/Modify\n- `tests/integration/workflows/planning-workflow.spec.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; mkdir -p tests/integration/workflows\"`.\n2. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > tests/integration/workflows/planning-workflow.spec.ts\nimport { runPlanningWorkflow } from '../../../src/core/workflows/planning-workflow.js';\nimport { promises as fs } from 'fs';\nimport { join } from 'path';\n\ndescribe('runPlanningWorkflow', () => {\n  const specPath = join(process.cwd(), 'tmp-spec.md');\n\n  beforeAll(async () => {\n    await fs.writeFile(specPath, '<SPEC_CONTENT>');\n  });\n\n  afterAll(async () => {\n    await fs.unlink(specPath);\n  });\n\n  it('completes when specification file is populated', async () => {\n    await expect(runPlanningWorkflow({ force: false, specificationPath: specPath })).resolves.toBeUndefined();\n  });\n});\nEOF\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add tests/integration/workflows/planning-workflow.spec.ts\"`.\n\n### Verification\n- `npm run test -- tests/integration/workflows/planning-workflow.spec.ts` exits 0.\n\n### Rollback\nRun `git restore --staged tests/integration/workflows/planning-workflow.spec.ts` then `git checkout -- tests/integration/workflows/planning-workflow.spec.ts`.\n\n### Variables\n- <SPEC_CONTENT>: Minimal specification text used for testing.\n",
          "blockedBy": [
            "T6.1",
            "T6.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T6_TEST",
      "name": "Test Create /start command and planning handshake",
      "phase": "Testing",
      "dependsOn": [
        "T6"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Create /start command and planning handshake' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T6 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T6 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T6's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T6.\n\n### Rollback\nAddress deficiencies in Task T6 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T6.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T6_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T6.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T6_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T7",
      "name": "Implement agent registry and prompt hydration",
      "phase": "Building",
      "done": true,
      "dependsOn": [
        "T6_TEST"
      ],
      "acceptanceCriteria": "Registry module loads `inputs/agents.js`, resolves prompt paths, and exposes query helpers with unit tests.",
      "details": "### Purpose\nProvide a single source of truth for available agents and prompt resolution.\n\n### Preconditions\n- Tasks T1-T6 complete\n\n### Artifacts To Create/Modify\n- `src/agents/registry/index.ts`\n- `src/agents/registry/agent-registry.test.ts` (unit test)\n- `docs/reference/agents.md`\n\n### Step-by-Step\n1. Implement registry module (subtask T7.1).\n2. Add unit tests verifying hydration (subtask T7.2).\n3. Document available agents (subtask T7.3).\n\n### Verification\n- `npm run typecheck -- src/agents/registry/index.ts` exits 0.\n- `npm run test -- src/agents/registry/agent-registry.test.ts` exits 0.\n- `rg 'frontend-dev' docs/reference/agents.md` returns entry.\n\n### Rollback\nRun `git restore src/agents/registry/index.ts src/agents/registry/agent-registry.test.ts docs/reference/agents.md`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T7.1",
          "name": "Create registry module",
          "details": "### Purpose\nLoad agent definitions from `inputs/agents.js` and resolve prompt paths.\n\n### Preconditions\n- Node can import CommonJS modules.\n\n### Artifacts To Create/Modify\n- `src/agents/registry/index.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/agents/registry/index.ts\nimport path from 'node:path';\nimport { pathToFileURL } from 'node:url';\n\nexport interface AgentDefinition {\n  id: string;\n  name: string;\n  description: string;\n  promptPath: string;\n}\n\nexport async function loadAgents(baseDir: string): Promise<AgentDefinition[]> {\n  const modulePath = path.join(baseDir, 'inputs', 'agents.js');\n  const { default: agents = [] } = await import(pathToFileURL(modulePath).href);\n  return (agents as AgentDefinition[]).map((agent) => ({\n    ...agent,\n    promptPath: path.resolve(baseDir, agent.promptPath)\n  }));\n}\n\nexport async function findAgent(id: string, baseDir: string): Promise<AgentDefinition | undefined> {\n  const agents = await loadAgents(baseDir);\n  return agents.find((agent) => agent.id === id);\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/agents/registry/index.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/agents/registry/index.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/agents/registry/index.ts` then `git checkout -- src/agents/registry/index.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T7.2",
          "name": "Write registry unit tests",
          "details": "### Purpose\nEnsure agent metadata loads and resolves prompt paths.\n\n### Preconditions\n- Subtask T7.1 staged.\n\n### Artifacts To Create/Modify\n- `src/agents/registry/agent-registry.test.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/agents/registry/agent-registry.test.ts\nimport path from 'node:path';\nimport { loadAgents, findAgent } from './index.js';\n\ndescribe('agent registry', () => {\n  const baseDir = path.resolve(__dirname, '../../..');\n\n  it('loads all configured agents', async () => {\n    const agents = await loadAgents(baseDir);\n    expect(agents.length).toBeGreaterThan(0);\n  });\n\n  it('resolves agent by id', async () => {\n    const agent = await findAgent('frontend-dev', baseDir);\n    expect(agent?.promptPath).toMatch(/prompts\\/frontend-developer\\.md$/);\n  });\n});\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/agents/registry/agent-registry.test.ts\"`.\n\n### Verification\n- `npm run test -- src/agents/registry/agent-registry.test.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/agents/registry/agent-registry.test.ts` then `git checkout -- src/agents/registry/agent-registry.test.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T7.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T7.3",
          "name": "Document agent catalogue",
          "details": "### Purpose\nPublish agent metadata for quick reference.\n\n### Preconditions\n- Subtasks T7.1 and T7.2 complete.\n\n### Artifacts To Create/Modify\n- `docs/reference/agents.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > docs/reference/agents.md\n# Agent Catalogue\n\n| ID | Name | Description | Prompt |\n|----|------|-------------|--------|\n| frontend-dev | Frontend Developer | Implements client-side code | prompts/frontend-developer.md |\n| backend-dev | Backend Developer | Builds server-side logic | prompts/backend-developer.md |\n| uxui-designer | UX/UI Designer | Designs UI system | prompts/ux-ui-designer.md |\n| solution-architect | Solution Architect | Designs solution architecture | prompts/solution-architect.md |\n| software-architect | Software Architect | Plans directories | prompts/software-architect.md |\n| technical-writer | Technical Writer | Creates documentation | prompts/technical-writer.md |\n| qa-engineer | QA/Test Engineer | Ensures quality | prompts/qa-test-engineer.md |\n| performance-engineer | Performance Engineer | Optimizes performance | prompts/performance-engineer.md |\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add docs/reference/agents.md\"`.\n\n### Verification\n- `rg 'Agent Catalogue' docs/reference/agents.md` returns heading.\n\n### Rollback\nRun `git restore --staged docs/reference/agents.md` then `git checkout -- docs/reference/agents.md`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T7.1",
            "T7.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T7_TEST",
      "name": "Test Implement agent registry and prompt hydration",
      "phase": "Testing",
      "dependsOn": [
        "T7"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Implement agent registry and prompt hydration' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T7 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T7 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T7's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T7.\n\n### Rollback\nAddress deficiencies in Task T7 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T7.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T7_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T7.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T7_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T8",
      "name": "Build Codex execution adapter",
      "phase": "Building",
      "done": true,
      "dependsOn": [
        "T7_TEST"
      ],
      "acceptanceCriteria": "`src/infra/codex/codex-runner.ts` invokes Codex CLI with streaming support, `src/infra/process/spawn.ts` abstracts process creation, and unit tests cover success/failure paths.",
      "details": "### Purpose\nProvide a resilient adapter for executing Codex CLI commands with streaming output.\n\n### Preconditions\n- Tasks T5-T7 complete\n\n### Artifacts To Create/Modify\n- `src/infra/process/spawn.ts`\n- `src/infra/codex/codex-runner.ts`\n- `tests/unit/infra/codex-runner.spec.ts`\n\n### Step-by-Step\n1. Implement process spawn helper (subtask T8.1).\n2. Implement Codex runner (subtask T8.2).\n3. Add unit tests with mocks (subtask T8.3).\n\n### Verification\n- `npm run typecheck -- src/infra/process/spawn.ts src/infra/codex/codex-runner.ts` exits 0.\n- `npm run test -- tests/unit/infra/codex-runner.spec.ts` exits 0.\n\n### Rollback\nRun `git restore src/infra/process/spawn.ts src/infra/codex/codex-runner.ts tests/unit/infra/codex-runner.spec.ts`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T8.1",
          "name": "Implement process spawn helper",
          "details": "### Purpose\nEncapsulate child_process spawning with promise-based API.\n\n### Preconditions\n- Node.js >= <NODE_VERSION>.\n\n### Artifacts To Create/Modify\n- `src/infra/process/spawn.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/infra/process/spawn.ts\nimport { spawn } from 'node:child_process';\n\nexport interface SpawnOptions {\n  command: string;\n  args: string[];\n  cwd?: string;\n  env?: NodeJS.ProcessEnv;\n}\n\nexport function spawnProcess(options: SpawnOptions): Promise<{ exitCode: number; stdout: string; stderr: string; }> {\n  return new Promise((resolve, reject) => {\n    const child = spawn(options.command, options.args, {\n      cwd: options.cwd,\n      env: options.env,\n      stdio: ['ignore', 'pipe', 'pipe']\n    });\n\n    let stdout = '';\n    let stderr = '';\n\n    child.stdout?.on('data', (chunk) => {\n      stdout += chunk.toString();\n    });\n\n    child.stderr?.on('data', (chunk) => {\n      stderr += chunk.toString();\n    });\n\n    child.on('error', (error) => reject(error));\n    child.on('close', (code) => resolve({ exitCode: code ?? 0, stdout, stderr }));\n  });\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/infra/process/spawn.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/infra/process/spawn.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/infra/process/spawn.ts` then `git checkout -- src/infra/process/spawn.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T8.2",
          "name": "Implement Codex runner",
          "details": "### Purpose\nWrap Codex CLI invocation with streaming callback support.\n\n### Preconditions\n- Subtask T8.1 staged.\n\n### Artifacts To Create/Modify\n- `src/infra/codex/codex-runner.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/infra/codex/codex-runner.ts\nimport path from 'node:path';\nimport { spawnProcess } from '../process/spawn.js';\n\ninterface CodexRunnerOptions {\n  profile: string;\n  prompt: string;\n  workingDir: string;\n  onData?: (chunk: string) => void;\n}\n\nexport async function runCodex(options: CodexRunnerOptions): Promise<string> {\n  const args = [\n    'exec',\n    '--profile', options.profile,\n    '--skip-git-repo-check',\n    '--sandbox', 'danger-full-access',\n    '--dangerously-bypass-approvals-and-sandbox',\n    '-C', options.workingDir,\n    options.prompt\n  ];\n\n  const result = await spawnProcess({\n    command: path.join(process.env.CODEX_HOME ?? '', 'bin', 'codex'),\n    args,\n    cwd: options.workingDir,\n    env: process.env\n  });\n\n  if (result.exitCode !== 0) {\n    throw new Error(`Codex exited with code ${result.exitCode}: ${result.stderr}`);\n  }\n\n  if (options.onData) {\n    options.onData(result.stdout);\n  }\n\n  return result.stdout;\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/infra/codex/codex-runner.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/infra/codex/codex-runner.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/infra/codex/codex-runner.ts` then `git checkout -- src/infra/codex/codex-runner.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T8.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T8.3",
          "name": "Add Codex runner unit tests",
          "details": "### Purpose\nValidate success, failure, and streaming callbacks using mocks.\n\n### Preconditions\n- Subtasks T8.1 and T8.2 complete.\n\n### Artifacts To Create/Modify\n- `tests/unit/infra/codex-runner.spec.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; mkdir -p tests/unit/infra\"`.\n2. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > tests/unit/infra/codex-runner.spec.ts\nimport { vi, describe, it, expect } from 'vitest';\nimport * as processModule from '../../../src/infra/process/spawn.js';\nimport { runCodex } from '../../../src/infra/codex/codex-runner.js';\n\ndescribe('runCodex', () => {\n  it('returns stdout when exit code is zero', async () => {\n    vi.spyOn(processModule, 'spawnProcess').mockResolvedValue({ exitCode: 0, stdout: '<CODEX_OUTPUT>', stderr: '' });\n    const output = await runCodex({ profile: 'frontend-dev', prompt: 'hello', workingDir: process.cwd() });\n    expect(output).toBe('<CODEX_OUTPUT>');\n  });\n\n  it('throws on non-zero exit code', async () => {\n    vi.spyOn(processModule, 'spawnProcess').mockResolvedValue({ exitCode: 2, stdout: '', stderr: 'error' });\n    await expect(runCodex({ profile: 'frontend-dev', prompt: 'hello', workingDir: process.cwd() })).rejects.toThrow('Codex exited with code 2');\n  });\n});\nEOF\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add tests/unit/infra/codex-runner.spec.ts\"`.\n\n### Verification\n- `npm run test -- tests/unit/infra/codex-runner.spec.ts` exits 0.\n\n### Rollback\nRun `git restore --staged tests/unit/infra/codex-runner.spec.ts` then `git checkout -- tests/unit/infra/codex-runner.spec.ts`.\n\n### Variables\n- <CODEX_OUTPUT>: Expected mock Codex output string.\n",
          "blockedBy": [
            "T8.1",
            "T8.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T8_TEST",
      "name": "Test Build Codex execution adapter",
      "phase": "Testing",
      "dependsOn": [
        "T8"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Build Codex execution adapter' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T8 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T8 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T8's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T8.\n\n### Rollback\nAddress deficiencies in Task T8 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T8.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T8_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T8.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T8_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T9",
      "name": "Implement CLI presentation layer",
      "phase": "Building",
      "done": true,
      "dependsOn": [
        "T6_TEST"
      ],
      "acceptanceCriteria": "Layout and typewriter utilities exist under `src/cli/presentation/`, documentation describes UI guidelines, and unit tests cover renderer configuration.",
      "details": "### Purpose\nProvide reusable presentation helpers for terminal UI consistent with Gemini-inspired design.\n\n### Preconditions\n- Tasks T5-T6 complete\n\n### Artifacts To Create/Modify\n- `src/cli/presentation/layout.ts`\n- `src/cli/presentation/typewriter.ts`\n- `docs/reference/cli-ui.md`\n\n### Step-by-Step\n1. Implement layout helper (subtask T9.1).\n2. Implement typewriter renderer (subtask T9.2).\n3. Document UI guidelines (subtask T9.3).\n\n### Verification\n- `npm run typecheck -- src/cli/presentation/layout.ts src/cli/presentation/typewriter.ts` exits 0.\n- `rg 'Typewriter' docs/reference/cli-ui.md` returns entry.\n\n### Rollback\nRun `git restore src/cli/presentation/layout.ts src/cli/presentation/typewriter.ts docs/reference/cli-ui.md`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T9.1",
          "name": "Create layout helper",
          "details": "### Purpose\nCentralize CLI layout width and color tokens.\n\n### Preconditions\n- None.\n\n### Artifacts To Create/Modify\n- `src/cli/presentation/layout.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/cli/presentation/layout.ts\nimport chalk from 'chalk';\n\nexport const palette = {\n  primary: chalk.hex('#3A7DFF'),\n  secondary: chalk.hex('#0B1F44'),\n  success: chalk.green,\n  warning: chalk.yellow,\n  error: chalk.red\n};\n\nexport function banner(text: string): string {\n  return palette.primary.bold(text);\n}\n\nexport function section(title: string): string {\n  return `\n${palette.secondary.bold(title)}\n`;\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/cli/presentation/layout.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/cli/presentation/layout.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/cli/presentation/layout.ts` then `git checkout -- src/cli/presentation/layout.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T9.2",
          "name": "Implement typewriter renderer",
          "details": "### Purpose\nStream output character-by-character with configurable speed.\n\n### Preconditions\n- Subtask T9.1 staged.\n\n### Artifacts To Create/Modify\n- `src/cli/presentation/typewriter.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/cli/presentation/typewriter.ts\nexport interface TypewriterOptions {\n  text: string;\n  intervalMs?: number;\n  onChunk?: (chunk: string) => void;\n}\n\nexport async function renderTypewriter(options: TypewriterOptions): Promise<void> {\n  const { text, intervalMs = <TYPEWRITER_INTERVAL>, onChunk } = options;\n  for (const char of text) {\n    process.stdout.write(char);\n    onChunk?.(char);\n    await new Promise((resolve) => setTimeout(resolve, intervalMs));\n  }\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/cli/presentation/typewriter.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/cli/presentation/typewriter.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/cli/presentation/typewriter.ts` then `git checkout -- src/cli/presentation/typewriter.ts`.\n\n### Variables\n- <TYPEWRITER_INTERVAL>: Default delay per character in milliseconds (e.g., 8).\n",
          "blockedBy": [
            "T9.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T9.3",
          "name": "Document CLI UI guidelines",
          "details": "### Purpose\nShare presentation rules with frontend developers and designers.\n\n### Preconditions\n- Subtasks T9.1 and T9.2 complete.\n\n### Artifacts To Create/Modify\n- `docs/reference/cli-ui.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > docs/reference/cli-ui.md\n# CLI UI Guidelines\n\n- Use `palette.primary` for banners and headers.\n- Keep typewriter interval between <MIN_INTERVAL> and <MAX_INTERVAL> ms.\n- Preserve accessibility by echoing plain text logs alongside colored output.\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add docs/reference/cli-ui.md\"`.\n\n### Verification\n- `rg 'CLI UI Guidelines' docs/reference/cli-ui.md` returns heading.\n\n### Rollback\nRun `git restore --staged docs/reference/cli-ui.md` then `git checkout -- docs/reference/cli-ui.md`.\n\n### Variables\n- <MIN_INTERVAL>: Minimum typewriter delay (e.g., 4).\n- <MAX_INTERVAL>: Maximum typewriter delay (e.g., 16).\n",
          "blockedBy": [
            "T9.1",
            "T9.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T9_TEST",
      "name": "Test Implement CLI presentation layer",
      "phase": "Testing",
      "dependsOn": [
        "T9"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Implement CLI presentation layer' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T9 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T9 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T9's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T9.\n\n### Rollback\nAddress deficiencies in Task T9 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T9.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T9_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T9.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T9_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T10",
      "name": "Implement memory persistence and analytics hooks",
      "phase": "Building",
      "done": true,
      "dependsOn": [
        "T8_TEST"
      ],
      "acceptanceCriteria": "Memory store reads/writes `.codemachine/memory`, filesystem adapter wraps persistence, and unit tests validate behavior.",
      "details": "### Purpose\nPersist agent outputs and analytics for replay while maintaining idempotence.\n\n### Preconditions\n- Tasks T5-T9 complete\n\n### Artifacts To Create/Modify\n- `src/agents/memory/memory-store.ts`\n- `src/infra/fs/memory-adapter.ts`\n- `tests/unit/agents/memory-store.spec.ts`\n\n### Step-by-Step\n1. Implement memory store API (subtask T10.1).\n2. Implement filesystem adapter (subtask T10.2).\n3. Add unit tests for persistence (subtask T10.3).\n\n### Verification\n- `npm run typecheck -- src/agents/memory/memory-store.ts src/infra/fs/memory-adapter.ts` exits 0.\n- `npm run test -- tests/unit/agents/memory-store.spec.ts` exits 0.\n\n### Rollback\nRun `git restore src/agents/memory/memory-store.ts src/infra/fs/memory-adapter.ts tests/unit/agents/memory-store.spec.ts`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T10.1",
          "name": "Implement memory store",
          "details": "### Purpose\nExpose CRUD operations for agent memory entries.\n\n### Preconditions\n- Node.js >= <NODE_VERSION>.\n\n### Artifacts To Create/Modify\n- `src/agents/memory/memory-store.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/agents/memory/memory-store.ts\nimport { MemoryAdapter } from '../../infra/fs/memory-adapter.js';\n\nexport interface MemoryEntry {\n  agentId: string;\n  content: string;\n  timestamp: string;\n}\n\nexport class MemoryStore {\n  constructor(private readonly adapter: MemoryAdapter) {}\n\n  async append(entry: MemoryEntry): Promise<void> {\n    await this.adapter.append(entry);\n  }\n\n  async list(agentId: string): Promise<MemoryEntry[]> {\n    return this.adapter.read(agentId);\n  }\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/agents/memory/memory-store.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/agents/memory/memory-store.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/agents/memory/memory-store.ts` then `git checkout -- src/agents/memory/memory-store.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T10.2",
          "name": "Implement filesystem memory adapter",
          "details": "### Purpose\nProvide persistence layer using `.codemachine/memory` directory.\n\n### Preconditions\n- Subtask T10.1 staged.\n\n### Artifacts To Create/Modify\n- `src/infra/fs/memory-adapter.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/infra/fs/memory-adapter.ts\nimport { promises as fs } from 'fs';\nimport path from 'node:path';\nimport { MemoryEntry } from '../../agents/memory/memory-store.js';\n\nexport class MemoryAdapter {\n  constructor(private readonly baseDir: string) {}\n\n  private fileFor(agentId: string): string {\n    return path.join(this.baseDir, `${agentId}.json`);\n  }\n\n  async append(entry: MemoryEntry): Promise<void> {\n    const file = this.fileFor(entry.agentId);\n    const existing = await this.read(entry.agentId);\n    existing.push(entry);\n    await fs.mkdir(this.baseDir, { recursive: true });\n    await fs.writeFile(file, JSON.stringify(existing, null, 2));\n  }\n\n  async read(agentId: string): Promise<MemoryEntry[]> {\n    const file = this.fileFor(agentId);\n    try {\n      const json = await fs.readFile(file, 'utf8');\n      return JSON.parse(json);\n    } catch (error: any) {\n      if (error.code === 'ENOENT') {\n        return [];\n      }\n      throw error;\n    }\n  }\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/infra/fs/memory-adapter.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/infra/fs/memory-adapter.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/infra/fs/memory-adapter.ts` then `git checkout -- src/infra/fs/memory-adapter.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T10.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T10.3",
          "name": "Add memory store unit tests",
          "details": "### Purpose\nEnsure append and read behavior works as expected.\n\n### Preconditions\n- Subtasks T10.1 and T10.2 complete.\n\n### Artifacts To Create/Modify\n- `tests/unit/agents/memory-store.spec.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; mkdir -p tests/unit/agents\"`.\n2. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > tests/unit/agents/memory-store.spec.ts\nimport { promises as fs } from 'fs';\nimport path from 'node:path';\nimport { MemoryAdapter } from '../../../src/infra/fs/memory-adapter.js';\nimport { MemoryStore } from '../../../src/agents/memory/memory-store.js';\n\ndescribe('MemoryStore', () => {\n  const tmpDir = path.join(process.cwd(), '.tmp', 'memory-tests');\n\n  afterEach(async () => {\n    await fs.rm(tmpDir, { recursive: true, force: true });\n  });\n\n  it('appends and lists entries', async () => {\n    const adapter = new MemoryAdapter(tmpDir);\n    const store = new MemoryStore(adapter);\n    await store.append({ agentId: 'frontend-dev', content: '<MEMORY_CONTENT>', timestamp: new Date().toISOString() });\n    const entries = await store.list('frontend-dev');\n    expect(entries).toHaveLength(1);\n  });\n});\nEOF\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add tests/unit/agents/memory-store.spec.ts\"`.\n\n### Verification\n- `npm run test -- tests/unit/agents/memory-store.spec.ts` exits 0.\n\n### Rollback\nRun `git restore --staged tests/unit/agents/memory-store.spec.ts` then `git checkout -- tests/unit/agents/memory-store.spec.ts`.\n\n### Variables\n- <MEMORY_CONTENT>: Sample content string used in test.\n",
          "blockedBy": [
            "T10.1",
            "T10.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T10_TEST",
      "name": "Test Implement memory persistence and analytics hooks",
      "phase": "Testing",
      "dependsOn": [
        "T10"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Implement memory persistence and analytics hooks' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T10 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T10 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T10's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T10.\n\n### Rollback\nAddress deficiencies in Task T10 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T10.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T10_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T10.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T10_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T11",
      "name": "Configure linting and unit test harness",
      "phase": "Testing",
      "done": true,
      "dependsOn": [
        "T5_TEST"
      ],
      "acceptanceCriteria": "`eslint.config.js` enforces project standards (`npx eslint --print-config src/app/index.ts` works), `vitest.config.ts` defines environment and setup files, and `tests/setup.ts` initializes mocks.",
      "details": "\n### Purpose\nEstablish linting and unit-test harness configuration compatible with the ESLint flat config and Vitest environment.\n\n### Preconditions\n- npm dependencies installed\n\n### Artifacts To Create/Modify\n- `eslint.config.js`\n- `vitest.config.ts`\n- `tests/setup.ts`\n\n### Step-by-Step\n1. Update the ESLint configuration (subtask T11.1).\n2. Ensure Vitest configuration wires the test environment (subtask T11.2).\n3. Add shared test setup to reset mocks (subtask T11.3).\n\n### Verification\n- `npx eslint --print-config src/app/index.ts` succeeds.\n- `pnpm vitest run tests/unit/cli/register-cli.spec.ts --coverage=false` succeeds after setup.\n\n### Rollback\nRemove changes to the listed artifacts.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T11.1",
          "name": "Create ESLint config",
          "details": "### Purpose\nDefine linting rules aligned with project guidelines.\n\n### Preconditions\n- ESLint installed (per package.json).\n\n### Artifacts To Create/Modify\n- `.eslintrc.cjs`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > .eslintrc.cjs\nmodule.exports = {\n  root: true,\n  env: { node: true, es2022: true },\n  extends: ['eslint:recommended', 'plugin:@typescript-eslint/recommended', 'prettier'],\n  parser: '@typescript-eslint/parser',\n  parserOptions: { project: './tsconfig.json' },\n  plugins: ['@typescript-eslint'],\n  ignorePatterns: ['dist', 'node_modules', '.tmp'],\n  rules: {\n    '@typescript-eslint/explicit-module-boundary-types': 'off',\n    '@typescript-eslint/no-explicit-any': 'error'\n  }\n};\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add .eslintrc.cjs\"`.\n\n### Verification\n- `npx eslint src/app/index.ts` exits 0.\n\n### Rollback\nRun `git restore --staged .eslintrc.cjs` then `git checkout -- .eslintrc.cjs`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": true
        },
        {
          "id": "T11.2",
          "name": "Create Vitest config",
          "details": "### Purpose\nConfigure Vitest for TypeScript project.\n\n### Preconditions\n- Vitest installed.\n\n### Artifacts To Create/Modify\n- `vitest.config.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > vitest.config.ts\nimport { defineConfig } from 'vitest/config';\n\nexport default defineConfig({\n  test: {\n    environment: 'node',\n    setupFiles: ['./tests/unit/setup.ts'],\n    coverage: { provider: 'c8', reporter: ['text', 'lcov'] }\n  }\n});\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add vitest.config.ts\"`.\n\n### Verification\n- `npm run test -- --dry-run` exits 0.\n\n### Rollback\nRun `git restore --staged vitest.config.ts` then `git checkout -- vitest.config.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T11.3",
          "name": "Add unit test setup file",
          "details": "### Purpose\nInitialize shared mocks/log suppression for tests.\n\n### Preconditions\n- Subtask T11.2 complete.\n\n### Artifacts To Create/Modify\n- `tests/unit/setup.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > tests/unit/setup.ts\nimport { afterEach, vi } from 'vitest';\n\nafterEach(() => {\n  vi.restoreAllMocks();\n});\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add tests/unit/setup.ts\"`.\n\n### Verification\n- `rg 'restoreAllMocks' tests/unit/setup.ts` returns entry.\n\n### Rollback\nRun `git restore --staged tests/unit/setup.ts` then `git checkout -- tests/unit/setup.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T11.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T11_TEST",
      "name": "Test Configure linting and unit test harness",
      "phase": "Testing",
      "dependsOn": [
        "T11"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Configure linting and unit test harness' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T11 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T11 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T11's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T11.\n\n### Rollback\nAddress deficiencies in Task T11 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T11.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T11_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T11.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T11_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T12",
      "name": "Create integration tests for workflows",
      "phase": "Testing",
      "done": true,
      "dependsOn": [
        "T6_TEST",
        "T7_TEST"
      ],
      "acceptanceCriteria": "Fixtures exist for planning tasks, integration tests cover Master Mind workflow, and documentation explains integration strategy.",
      "details": "### Purpose\nValidate cross-module interactions using realistic fixtures.\n\n### Preconditions\n- Tasks T6 and T7 complete\n\n### Artifacts To Create/Modify\n- `tests/fixtures/tasks/planning.json`\n- `tests/integration/workflows/master-mind.spec.ts`\n- `docs/reference/testing/integration/index.md`\n\n### Step-by-Step\n1. Prepare planning fixture data (subtask T12.1).\n2. Write integration test (subtask T12.2).\n3. Document integration testing approach (subtask T12.3).\n\n### Verification\n- `test -f tests/fixtures/tasks/planning.json` exits 0.\n- `npm run test -- tests/integration/workflows/master-mind.spec.ts` exits 0.\n- `rg 'Integration Testing' docs/reference/testing/integration/index.md` returns heading.\n\n### Rollback\nRun `git restore tests/fixtures/tasks/planning.json tests/integration/workflows/master-mind.spec.ts docs/reference/testing/integration/index.md`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T12.1",
          "name": "Create planning fixture",
          "details": "### Purpose\nSupply deterministic task data for integration tests.\n\n### Preconditions\n- None.\n\n### Artifacts To Create/Modify\n- `tests/fixtures/tasks/planning.json`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; mkdir -p tests/fixtures/tasks\"`.\n2. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > tests/fixtures/tasks/planning.json\n{\n  \"tasks\": [\n    {\n      \"id\": \"T1\",\n      \"phase\": \"Planning\",\n      \"description\": \"<PLANNING_FIXTURE_DESCRIPTION>\"\n    }\n  ]\n}\nEOF\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add tests/fixtures/tasks/planning.json\"`.\n\n### Verification\n- `jq '.tasks[0].phase' tests/fixtures/tasks/planning.json` outputs `\"Planning\"`.\n\n### Rollback\nRun `git restore --staged tests/fixtures/tasks/planning.json` then `git checkout -- tests/fixtures/tasks/planning.json`.\n\n### Variables\n- <PLANNING_FIXTURE_DESCRIPTION>: Brief description of planning fixture scenario.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T12.2",
          "name": "Add master mind workflow test",
          "details": "### Purpose\nSimulate Master Mind executing planning tasks using fixtures.\n\n### Preconditions\n- Subtask T12.1 complete.\n\n### Artifacts To Create/Modify\n- `tests/integration/workflows/master-mind.spec.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > tests/integration/workflows/master-mind.spec.ts\nimport { describe, it, expect } from 'vitest';\nimport planningFixture from '../../fixtures/tasks/planning.json';\n\n// <MASTER_MIND_IMPORTS>\n\ndescribe('Master Mind workflow', () => {\n  it('handles planning fixture', async () => {\n    const result = await <MASTER_MIND_EXECUTION>(planningFixture);\n    expect(result.phase).toBe('Building');\n  });\n});\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add tests/integration/workflows/master-mind.spec.ts\"`.\n\n### Verification\n- `npm run test -- tests/integration/workflows/master-mind.spec.ts` exits 0.\n\n### Rollback\nRun `git restore --staged tests/integration/workflows/master-mind.spec.ts` then `git checkout -- tests/integration/workflows/master-mind.spec.ts`.\n\n### Variables\n- <MASTER_MIND_IMPORTS>: Imports for workflow executor.\n- <MASTER_MIND_EXECUTION>: Function call executing workflow.\n",
          "blockedBy": [
            "T12.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T12.3",
          "name": "Document integration testing strategy",
          "details": "### Purpose\nProvide guidance for creating and maintaining integration tests.\n\n### Preconditions\n- Subtasks T12.1 and T12.2 complete.\n\n### Artifacts To Create/Modify\n- `docs/reference/testing/integration/index.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; mkdir -p docs/reference/testing/integration\"`.\n2. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > docs/reference/testing/integration/index.md\n# Integration Testing\n\n- Use fixtures from `tests/fixtures` to drive deterministic scenarios.\n- Ensure each workflow test advances the phase to the expected next phase.\n- Record new fixtures in the assumptions log when they introduce constraints.\nEOF\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add docs/reference/testing/integration/index.md\"`.\n\n### Verification\n- `rg 'Integration Testing' docs/reference/testing/integration/index.md` returns heading.\n\n### Rollback\nRun `git restore --staged docs/reference/testing/integration/index.md` then `git checkout -- docs/reference/testing/integration/index.md`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T12.1",
            "T12.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T12_TEST",
      "name": "Test Create integration tests for workflows",
      "phase": "Testing",
      "dependsOn": [
        "T12"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Create integration tests for workflows' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T12 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T12 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T12's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T12.\n\n### Rollback\nAddress deficiencies in Task T12 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T12.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T12_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T12.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T12_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T13",
      "name": "Implement E2E CLI smoke suite",
      "phase": "Testing",
      "done": true,
      "dependsOn": [
        "T5_TEST",
        "T8_TEST"
      ],
      "acceptanceCriteria": "E2E test simulates CLI start run, mock Codex response fixture exists, and CI script executes suite.",
      "details": "### Purpose\nEnsure high-level CLI workflow functions when executed end-to-end.\n\n### Preconditions\n- Tasks T5-T8 complete\n\n### Artifacts To Create/Modify\n- `tests/e2e/start-cli.spec.ts`\n- `tests/fixtures/codex/mock-response.json`\n- `scripts/ci/run-e2e.sh`\n\n### Step-by-Step\n1. Prepare Codex mock response fixture (subtask T13.1).\n2. Write E2E test (subtask T13.2).\n3. Create CI script to run E2E suite (subtask T13.3).\n\n### Verification\n- `npm run test -- tests/e2e/start-cli.spec.ts` exits 0 (with mocks).\n- `bash -lc \"set -euo pipefail; scripts/ci/run-e2e.sh\"` exits 0.\n\n### Rollback\nRun `git restore tests/e2e/start-cli.spec.ts tests/fixtures/codex/mock-response.json scripts/ci/run-e2e.sh`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T13.1",
          "name": "Create Codex mock response",
          "details": "### Purpose\nProvide deterministic Codex output for E2E tests.\n\n### Preconditions\n- None.\n\n### Artifacts To Create/Modify\n- `tests/fixtures/codex/mock-response.json`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; mkdir -p tests/fixtures/codex\"`.\n2. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > tests/fixtures/codex/mock-response.json\n{\n  \"output\": \"<MOCK_CODEX_OUTPUT>\",\n  \"status\": \"success\"\n}\nEOF\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add tests/fixtures/codex/mock-response.json\"`.\n\n### Verification\n- `jq '.status' tests/fixtures/codex/mock-response.json` outputs `\"success\"`.\n\n### Rollback\nRun `git restore --staged tests/fixtures/codex/mock-response.json` then `git checkout -- tests/fixtures/codex/mock-response.json`.\n\n### Variables\n- <MOCK_CODEX_OUTPUT>: Mock CLI output string.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T13.2",
          "name": "Write E2E test",
          "details": "### Purpose\nExecute CLI via Node child process and validate output.\n\n### Preconditions\n- Subtask T13.1 complete.\n\n### Artifacts To Create/Modify\n- `tests/e2e/start-cli.spec.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > tests/e2e/start-cli.spec.ts\nimport { execa } from 'execa';\nimport path from 'node:path';\n\ndescribe('CLI start command (E2E)', () => {\n  it('prints planning completion message', async () => {\n    const cliPath = path.join(process.cwd(), 'dist', 'index.js');\n    const { stdout } = await execa('node', [cliPath, 'start', '--force'], {\n      env: { CODEX_HOME: process.env.CODEX_HOME ?? '<CODEX_HOME>' }\n    });\n    expect(stdout).toContain('<E2E_EXPECTATION>');\n  });\n});\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add tests/e2e/start-cli.spec.ts\"`.\n\n### Verification\n- `npm run test -- tests/e2e/start-cli.spec.ts` exits 0 (with mocks).\n\n### Rollback\nRun `git restore --staged tests/e2e/start-cli.spec.ts` then `git checkout -- tests/e2e/start-cli.spec.ts`.\n\n### Variables\n- <CODEX_HOME>: Path to Codex home for test environment.\n- <E2E_EXPECTATION>: Expected output substring from CLI.\n",
          "blockedBy": [
            "T13.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T13.3",
          "name": "Create E2E CI script",
          "details": "### Purpose\nAutomate E2E test execution for CI pipelines.\n\n### Preconditions\n- Subtasks T13.1 and T13.2 complete.\n\n### Artifacts To Create/Modify\n- `scripts/ci/run-e2e.sh`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > scripts/ci/run-e2e.sh\n#!/usr/bin/env bash\nset -euo pipefail\n\nnpm run build\nCODEX_HOME=\\\"${CODEX_HOME:-<CODEX_HOME>}\\\" npm run test -- tests/e2e/start-cli.spec.ts\nEOF\"`.\n2. Run `bash -lc \"set -euo pipefail; chmod +x scripts/ci/run-e2e.sh\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add scripts/ci/run-e2e.sh\"`.\n\n### Verification\n- `bash -lc \"set -euo pipefail; scripts/ci/run-e2e.sh\"` exits 0.\n\n### Rollback\nRun `git restore --staged scripts/ci/run-e2e.sh` then `git checkout -- scripts/ci/run-e2e.sh`.\n\n### Variables\n- <CODEX_HOME>: Path to Codex home for CI runs.\n",
          "blockedBy": [
            "T13.1",
            "T13.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T13_TEST",
      "name": "Test Implement E2E CLI smoke suite",
      "phase": "Testing",
      "dependsOn": [
        "T13"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Implement E2E CLI smoke suite' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T13 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T13 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T13's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T13.\n\n### Rollback\nAddress deficiencies in Task T13 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T13.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T13_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T13.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T13_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T14",
      "name": "Automate packaging and release workflow",
      "phase": "Runtime",
      "done": true,
      "dependsOn": [
        "T10_TEST",
        "T11_TEST"
      ],
      "acceptanceCriteria": "`scripts/ops/publish.sh` runs npm publish with checks, package.json exposes release script, and release docs exist.",
      "details": "### Purpose\nProvide reproducible packaging and publishing process for releases.\n\n### Preconditions\n- npm authenticated with registry\n\n### Artifacts To Create/Modify\n- `scripts/ops/publish.sh`\n- `package.json`\n- `docs/operations/release.md`\n\n### Step-by-Step\n1. Update publish script (subtask T14.1).\n2. Add npm `release` script (subtask T14.2).\n3. Document release workflow (subtask T14.3).\n\n### Verification\n- `bash -lc \"set -euo pipefail; scripts/ops/publish.sh --dry-run\"` exits 0.\n- `jq -r '.scripts.release' package.json` outputs the release command.\n- `rg 'Release Workflow' docs/operations/release.md` returns heading.\n\n### Rollback\nRun `git restore scripts/ops/publish.sh package.json docs/operations/release.md`.\n\n### Variables\n- <NPM_TAG>: Release tag (e.g., latest, beta).\n",
      "subtasks": [
        {
          "id": "T14.1",
          "name": "Enhance publish script",
          "details": "### Purpose\nAdd build, validation, and publish steps with dry-run support.\n\n### Preconditions\n- Build and validate scripts available.\n\n### Artifacts To Create/Modify\n- `scripts/ops/publish.sh`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > scripts/ops/publish.sh\n#!/usr/bin/env bash\nset -euo pipefail\n\nDRY_RUN=false\nwhile [[ $# -gt 0 ]]; do\n  case $1 in\n    --dry-run) DRY_RUN=true; shift ;;\n    --tag) TAG=$2; shift 2 ;;\n    *) echo \"Unknown option $1\"; exit 1 ;;\n  esac\ndone\n\nnpm run validate\nnpm run build\n\nif [[ $DRY_RUN == true ]]; then\n  echo \"[publish] Dry run complete\"\nelse\n  npm publish --access public ${TAG:+--tag $TAG}\nfi\nEOF\"`.\n2. Run `bash -lc \"set -euo pipefail; chmod +x scripts/ops/publish.sh\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add scripts/ops/publish.sh\"`.\n\n### Verification\n- `bash -lc \"set -euo pipefail; scripts/ops/publish.sh --dry-run\"` exits 0.\n\n### Rollback\nRun `git restore --staged scripts/ops/publish.sh` then `git checkout -- scripts/ops/publish.sh`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T14.2",
          "name": "Add npm release script",
          "details": "### Purpose\nExpose release workflow via npm scripts.\n\n### Preconditions\n- Subtask T14.1 complete.\n\n### Artifacts To Create/Modify\n- `package.json`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; node - <<'JS'\nconst fs = require('fs');\nconst pkg = JSON.parse(fs.readFileSync('package.json', 'utf8'));\npkg.scripts.release = 'scripts/ops/publish.sh';\nfs.writeFileSync('package.json', JSON.stringify(pkg, null, 2) + '\\n');\nJS\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add package.json\"`.\n\n### Verification\n- `jq -r '.scripts.release' package.json` outputs `scripts/ops/publish.sh`.\n\n### Rollback\nRun `git restore --staged package.json` then `git checkout -- package.json`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [
            "T14.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T14.3",
          "name": "Document release workflow",
          "details": "### Purpose\nProvide step-by-step instructions for preparing and publishing a release.\n\n### Preconditions\n- Subtasks T14.1 and T14.2 complete.\n\n### Artifacts To Create/Modify\n- `docs/operations/release.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > docs/operations/release.md\n# Release Workflow\n\n1. Run `npm run validate`\n2. Run `npm run build`\n3. Execute `npm run release -- --tag <NPM_TAG>`\n4. Update CHANGELOG (future task)\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add docs/operations/release.md\"`.\n\n### Verification\n- `rg 'Release Workflow' docs/operations/release.md` returns heading.\n\n### Rollback\nRun `git restore --staged docs/operations/release.md` then `git checkout -- docs/operations/release.md`.\n\n### Variables\n- <NPM_TAG>: Publish tag (e.g., latest, beta).\n",
          "blockedBy": [
            "T14.1",
            "T14.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T14_TEST",
      "name": "Test Automate packaging and release workflow",
      "phase": "Testing",
      "dependsOn": [
        "T14"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Automate packaging and release workflow' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T14 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T14 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T14's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T14.\n\n### Rollback\nAddress deficiencies in Task T14 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T14.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T14_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T14.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T14_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T15",
      "name": "Establish telemetry and rollback operations",
      "phase": "Runtime",
      "done": true,
      "dependsOn": [
        "T8_TEST",
        "T10_TEST"
      ],
      "acceptanceCriteria": "Logger factory exists, telemetry doc published, rollback script handles git revert and npm unpublish dry run.",
      "details": "### Purpose\nEnsure runtime observability and safe rollback procedures.\n\n### Preconditions\n- Logging dependencies available\n\n### Artifacts To Create/Modify\n- `src/shared/logging/logger.ts`\n- `docs/operations/telemetry.md`\n- `scripts/ops/rollback.sh`\n\n### Step-by-Step\n1. Implement logger factory (subtask T15.1).\n2. Document telemetry strategy (subtask T15.2).\n3. Create rollback script (subtask T15.3).\n\n### Verification\n- `npm run typecheck -- src/shared/logging/logger.ts` exits 0.\n- `rg 'Telemetry Strategy' docs/operations/telemetry.md` returns heading.\n- `bash -lc \"set -euo pipefail; scripts/ops/rollback.sh --dry-run\"` exits 0.\n\n### Rollback\nRun `git restore src/shared/logging/logger.ts docs/operations/telemetry.md scripts/ops/rollback.sh`.\n\n### Variables\n- <NODE_VERSION>: Required Node.js version (>=20.10.0).\n",
      "subtasks": [
        {
          "id": "T15.1",
          "name": "Create logger factory",
          "details": "### Purpose\nProvide Pino-based logger with redaction and level control.\n\n### Preconditions\n- Pino dependency installed.\n\n### Artifacts To Create/Modify\n- `src/shared/logging/logger.ts`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > src/shared/logging/logger.ts\nimport pino from 'pino';\n\nexport interface LoggerOptions {\n  level?: pino.Level\n}\n\nexport function createLogger(options: LoggerOptions = {}) {\n  return pino({\n    level: options.level ?? process.env.LOG_LEVEL ?? 'info',\n    redact: ['password', 'token']\n  });\n}\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add src/shared/logging/logger.ts\"`.\n\n### Verification\n- `npm run typecheck -- src/shared/logging/logger.ts` exits 0.\n\n### Rollback\nRun `git restore --staged src/shared/logging/logger.ts` then `git checkout -- src/shared/logging/logger.ts`.\n\n### Variables\n- <NO_PLACEHOLDERS>: Not applicable.\n",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T15.2",
          "name": "Document telemetry strategy",
          "details": "### Purpose\nDescribe logging, metrics, and privacy considerations.\n\n### Preconditions\n- Subtask T15.1 complete.\n\n### Artifacts To Create/Modify\n- `docs/operations/telemetry.md`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > docs/operations/telemetry.md\n# Telemetry Strategy\n\n- Logging provided by `src/shared/logging/logger.ts` with PII redaction.\n- Metrics exported to <METRICS_DESTINATION>.\n- Respect `TELEMETRY_ENABLED` flag before sending data.\nEOF\"`.\n2. Stage file with `bash -lc \"set -euo pipefail; git add docs/operations/telemetry.md\"`.\n\n### Verification\n- `rg 'Telemetry Strategy' docs/operations/telemetry.md` returns heading.\n\n### Rollback\nRun `git restore --staged docs/operations/telemetry.md` then `git checkout -- docs/operations/telemetry.md`.\n\n### Variables\n- <METRICS_DESTINATION>: Target metrics endpoint or log sink.\n",
          "blockedBy": [
            "T15.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T15.3",
          "name": "Create rollback script",
          "details": "### Purpose\nAutomate git reset and npm unpublish dry-run steps for failed releases.\n\n### Preconditions\n- Subtasks T15.1 and T15.2 complete.\n\n### Artifacts To Create/Modify\n- `scripts/ops/rollback.sh`\n\n### Step-by-Step\n1. Run `bash -lc \"set -euo pipefail; cat <<'EOF' > scripts/ops/rollback.sh\n#!/usr/bin/env bash\nset -euo pipefail\n\nDRY_RUN=false\nTAG='<NPM_TAG>'\n\nwhile [[ $# -gt 0 ]]; do\n  case $1 in\n    --dry-run) DRY_RUN=true; shift ;;\n    --tag) TAG=$2; shift 2 ;;\n    *) TAG=$1; shift ;;\n  esac\ndone\n\necho '[rollback] reverting commit and package (dry run: '\"$DRY_RUN\"')'\nif [[ $DRY_RUN == false ]]; then\n  git tag -d \"$TAG\" || true\n  git reset --hard HEAD~1\n  npm unpublish \"codemachine@$TAG\" --force\nelse\n  printf 'Dry run: git tag -d %s\\n' \"$TAG\"\n  printf 'Dry run: git reset --hard HEAD~1\\n'\n  printf 'Dry run: npm unpublish codemachine@%s --force\\n' \"$TAG\"\nfi\nEOF\"`.\n2. Run `bash -lc \"set -euo pipefail; chmod +x scripts/ops/rollback.sh\"`.\n3. Stage file with `bash -lc \"set -euo pipefail; git add scripts/ops/rollback.sh\"`.\n\n### Verification\n- `bash -lc \"set -euo pipefail; scripts/ops/rollback.sh --dry-run --tag <NPM_TAG>\"` prints dry-run messages.\n\n### Rollback\nRun `git restore --staged scripts/ops/rollback.sh` then `git checkout -- scripts/ops/rollback.sh`.\n\n### Variables\n- <NPM_TAG>: Release tag to roll back (e.g., latest, beta).\n",
          "blockedBy": [
            "T15.1",
            "T15.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T15_TEST",
      "name": "Test Establish telemetry and rollback operations",
      "phase": "Testing",
      "dependsOn": [
        "T15"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Establish telemetry and rollback operations' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T15 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T15 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T15's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T15.\n\n### Rollback\nAddress deficiencies in Task T15 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T15.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T15_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T15.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T15_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T16",
      "name": "Synchronize Codex configuration on CLI startup",
      "phase": "Runtime",
      "dependsOn": [
        "T5_TEST",
        "T7_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "Running `codemachine` rewrites `~/.codemachine/codex/config.toml` using agent profiles from `inputs/agents.js`, persists model reasoning fields exactly as in the spec, and automated tests confirm repeat runs are idempotent and respect the `CODEX_HOME` override.",
      "details": "### Purpose\nKeep Codex profiles aligned with project agents every time the CLI executes so the user never has to manually sync configuration.\n\n### Preconditions\n- CLI entrypoint implemented (Task T5).\n- Agent registry available (Task T7).\n\n### Artifacts To Create/Modify\n- `src/app/services/config-sync.ts` (or equivalent)\n- `tests/unit/app/config-sync.spec.ts`\n- Runtime hook inside CLI bootstrap\n\n### Step-by-Step\n1. Read and parse `inputs/agents.js`, mapping each agent to config sections (profile name, model, reasoning effort).\n2. Write the merged profile map to `~/.codemachine/codex/config.toml`, honoring the TOML structure shown in `runner-prompts/user-input.md`.\n3. Ensure the sync respects `CODEX_HOME` so tests can redirect to a temporary directory.\n4. Invoke the sync before the main menu renders so login status reflects latest configuration.\n\n### Verification\n- `npm run test -- tests/unit/app/config-sync.spec.ts` passes.\n- Manual run from a temporary home shows `config.toml` updated on consecutive executions without diff.\n\n### Rollback\nRemove the sync hook from CLI bootstrap and delete the generated service.",
      "subtasks": [
        {
          "id": "T16.1",
          "name": "Implement config sync service",
          "details": "Create a module that loads `inputs/agents.js`, transforms agent metadata into TOML, and writes to the resolved `CODEX_HOME` directory.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T16.2",
          "name": "Hook sync into CLI bootstrap",
          "details": "Call the config sync service before rendering the CLI main menu so every run refreshes `config.toml`.",
          "blockedBy": [
            "T16.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T16.3",
          "name": "Add config sync tests",
          "details": "Write unit tests that stub `CODEX_HOME`, confirm profile output matches the spec, and prove idempotent rewrites.",
          "blockedBy": [
            "T16.1"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T16_TEST",
      "name": "Test Synchronize Codex configuration on CLI startup",
      "phase": "Testing",
      "dependsOn": [
        "T16"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Synchronize Codex configuration on CLI startup' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T16 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T16 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T16's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T16.\n\n### Rollback\nAddress deficiencies in Task T16 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T16.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T16_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T16.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T16_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T17",
      "name": "Bootstrap project workspace structure on launch",
      "phase": "Building",
      "dependsOn": [
        "T5_TEST",
        "T16_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "On every CLI run, `.codemachine/agents/agents-config.json`, `.codemachine/inputs/specifications.md`, `.codemachine/memory/`, and `.codemachine/plan/` exist with agent data mirrored from `inputs/agents.js`; new project runs create a working directory under `projects/<name>/` when absent; and tests assert directory creation is idempotent and safe in empty projects.",
      "details": "\n### Purpose\nGuarantee the required workspace scaffolding exists so agents-builder and Master Mind can operate without manual setup.\n\n### Preconditions\n- CLI entrypoint functional (Task T5).\n- Config sync in place (Task T16).\n\n### Artifacts To Create/Modify\n- `src/app/services/workspace-bootstrap.ts`\n- `tests/unit/app/workspace-bootstrap.spec.ts`\n- `.codemachine/inputs/specifications.md` template\n\n### Step-by-Step\n1. Create the per-project working directory under `projects/<project-name>/` when missing and ensure the current run uses it as `process.cwd()`.\n2. Serialize the contents of `inputs/agents.js` to `.codemachine/agents/agents-config.json`.\n3. Ensure `inputs/specifications.md`, `memory/`, and `plan/` folders exist, preserving existing files.\n4. Document the bootstrap behavior for builders and Master Mind consumers.\n\n### Verification\n- `npm run test -- tests/unit/app/workspace-bootstrap.spec.ts` passes.\n- Manual run in a clean temp directory produces the expected tree structure from the spec.\n\n### Rollback\nRemove the bootstrap hook and delete generated files or directories.\n",
      "subtasks": [
        {
          "id": "T17.1",
          "name": "Create bootstrap service",
          "details": "Implement filesystem logic that makes the `.codemachine/` tree and writes `agents-config.json`.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T17.2",
          "name": "Seed specifications template",
          "details": "Provide a starter `.codemachine/inputs/specifications.md` so users know where to place requirements.",
          "blockedBy": [
            "T17.1"
          ],
          "canWorkInParallel": true
        },
        {
          "id": "T17.3",
          "name": "Test bootstrap idempotence",
          "details": "Write tests ensuring repeated runs do not clobber existing user content and still refresh agent metadata.",
          "blockedBy": [
            "T17.1"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T17_TEST",
      "name": "Test Bootstrap project workspace structure on launch",
      "phase": "Testing",
      "dependsOn": [
        "T17"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Bootstrap project workspace structure on launch' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T17 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T17 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T17's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T17.\n\n### Rollback\nAddress deficiencies in Task T17 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T17.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T17_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T17.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T17_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T18",
      "name": "Implement authentication flow and dynamic menu options",
      "phase": "Building",
      "dependsOn": [
        "T17_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "CLI detects `~/.codemachine/codex/auth/auth.json`, shows `/login` when missing and `/logout` when present, executes `CODEX_HOME=... codex login` during first-time setup, and updates the main menu after successful authentication per the spec.",
      "details": "### Purpose\nProvide a seamless login/logout experience that mirrors the documented first-time setup sequence.\n\n### Preconditions\n- Workspace bootstrap complete (Task T17).\n\n### Artifacts To Create/Modify\n- `src/app/services/auth-status.ts`\n- `src/cli/commands/auth.command.ts` enhancements\n- `tests/unit/cli/auth-flow.spec.ts`\n\n### Step-by-Step\n1. Detect the presence of `auth.json` under `~/.codemachine/codex/auth/`.\n2. Trigger `CODEX_HOME=\"$HOME/.codemachine/codex\" codex login` when the user selects `/login` and no credentials exist.\n3. After login, force a config sync (Task T16) and refresh the menu to expose `/start`, `/templates`, `/version`, `/help`, `/mcp`, and `/logout`.\n4. When `/logout` is selected, remove credentials and fall back to offering `/login`.\n\n### Verification\n- `npm run test -- tests/unit/cli/auth-flow.spec.ts` passes with mocked Codex commands.\n- Manual smoke test confirms menu toggles `/login` versus `/logout` correctly.\n\n### Rollback\nRemove added auth hooks and revert CLI command changes.",
      "subtasks": [
        {
          "id": "T18.1",
          "name": "Detect authentication status",
          "details": "Expose a helper that reports whether `auth.json` exists and is readable.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T18.2",
          "name": "Implement login/logout commands",
          "details": "Invoke the Codex CLI login flow with `CODEX_HOME` set, and handle credential removal for logout.",
          "blockedBy": [
            "T18.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T18.3",
          "name": "Update menu rendering",
          "details": "Ensure the main menu reflects authentication state and displays the command list described in the spec.",
          "blockedBy": [
            "T18.1"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T18_TEST",
      "name": "Test Implement authentication flow and dynamic menu options",
      "phase": "Testing",
      "dependsOn": [
        "T18"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Implement authentication flow and dynamic menu options' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T18 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T18 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T18's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T18.\n\n### Rollback\nAddress deficiencies in Task T18 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T18.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T18_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T18.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T18_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T19",
      "name": "Deliver branded CLI main menu and command navigation",
      "phase": "Building",
      "dependsOn": [
        "T9_TEST",
        "T18_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "Main menu renders the Gemini-inspired ASCII banner, shows `Mode: build`, lists `/start`, `/templates`, `/login|/logout`, `/version`, `/help`, `/mcp`, and prompts for specifications per the spec, with snapshot tests covering layout.",
      "details": "### Purpose\nMatch the documented user interface so operators experience the expected branding and command entry points.\n\n### Preconditions\n- Presentation helpers (Task T9).\n- Auth-driven menu toggles (Task T18).\n\n### Artifacts To Create/Modify\n- `src/cli/presentation/main-menu.ts`\n- `tests/unit/cli/presentation/main-menu.spec.ts`\n- Style guide updates in `docs/reference/cli-ui.md`\n\n### Step-by-Step\n1. Render the ASCII art header exactly as provided in `runner-prompts/user-input.md`.\n2. Display the command list and `Mode: build` using layout helpers.\n3. Append the reminder to verify `.codemachine/inputs/specifications.md`.\n4. Snapshot test the output to guard against regressions.\n\n### Verification\n- `npx vitest run tests/unit/cli/presentation/main-menu.spec.ts` passes.\n- Manual CLI run shows the banner and command table identical to the spec.\n\n### Rollback\nRevert menu rendering changes and remove snapshots.",
      "subtasks": [
        {
          "id": "T19.1",
          "name": "Render ASCII banner",
          "details": "Encode the multi-line title block and ensure colors match the palette.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T19.2",
          "name": "List main menu commands",
          "details": "Show `/start`, `/templates`, `/login|/logout`, `/version`, `/help`, `/mcp` with contextual descriptions.",
          "blockedBy": [
            "T19.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T19.3",
          "name": "Add presentation tests",
          "details": "Capture CLI output snapshots to ensure branding remains stable.",
          "blockedBy": [
            "T19.1"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T19_TEST",
      "name": "Test Deliver branded CLI main menu and command navigation",
      "phase": "Testing",
      "dependsOn": [
        "T19"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Deliver branded CLI main menu and command navigation' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T19 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T19 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T19's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T19.\n\n### Rollback\nAddress deficiencies in Task T19 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T19.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T19_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T19.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T19_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T20",
      "name": "Implement execution UI controls and typewriter streaming",
      "phase": "Building",
      "dependsOn": [
        "T9_TEST",
        "T19_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "During task execution the CLI streams output via the 12 ms typewriter helper, mirrors plain-text logs, handles first Ctrl+C as \"modify plan\" prompt, second Ctrl+C as exit, and Ctrl+E toggles expanded logs; tests cover keyboard handling and interval overrides (8â€“24 ms).",
      "details": "### Purpose\nProvide the interactive experience described for the execution screen, including accessibility and control shortcuts.\n\n### Preconditions\n- Presentation helpers shipped (Task T9).\n- Branded menus available (Task T19).\n\n### Artifacts To Create/Modify\n- `src/cli/presentation/execution-screen.ts`\n- `src/cli/controllers/keyboard-controls.ts`\n- `tests/unit/cli/execution-ui.spec.ts`\n\n### Step-by-Step\n1. Integrate `renderTypewriter` so Codex output streams with default 12 ms cadence and mirrors logs for accessibility.\n2. Implement keyboard handlers: first Ctrl+C opens a plan modification flow, second Ctrl+C exits; Ctrl+E toggles expanded logs.\n3. Display task metadata (task id, phase, timer) as shown in the spec.\n4. Write tests using fake timers to confirm streaming intervals and control flows.\n\n### Verification\n- `npx vitest run tests/unit/cli/execution-ui.spec.ts` passes.\n- Manual execution shows typewriter effect and control prompts behaving as documented.\n\n### Rollback\nRemove execution UI module and restore previous streaming behavior.",
      "subtasks": [
        {
          "id": "T20.1",
          "name": "Wire typewriter output",
          "details": "Use the presentation helper to stream Codex text with mirrored logging.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T20.2",
          "name": "Handle keyboard controls",
          "details": "Implement Ctrl+C (plan edit + exit) and Ctrl+E (expand logs) flows.",
          "blockedBy": [
            "T20.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T20.3",
          "name": "Test execution UI",
          "details": "Add Vitest coverage for streaming intervals and control branches using fake timers and simulated keypresses.",
          "blockedBy": [
            "T20.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T20_TEST",
      "name": "Test Implement execution UI controls and typewriter streaming",
      "phase": "Testing",
      "dependsOn": [
        "T20"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Implement execution UI controls and typewriter streaming' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T20 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T20 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T20's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T20.\n\n### Rollback\nAddress deficiencies in Task T20 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T20.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T20_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T20.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T20_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T21",
      "name": "Implement agent execution wrapper command",
      "phase": "Building",
      "dependsOn": [
        "T8_TEST",
        "T10_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "`codemachine --agent <name> \"<prompt>\"` constructs composite prompts (agent prompt + memory + request), runs `CODEX_HOME=... codex exec --profile <name> --skip-git-repo-check --sandbox danger-full-access --dangerously-bypass-approvals-and-sandbox -C <workingDir> \"<composite prompt>\"`, streams output, and appends sanitized logs to `.codemachine/memory/.<agent>-memory.md`.",
      "details": "\n### Purpose\nExpose the simplified command interface that Master Mind relies on for orchestration.\n\n### Preconditions\n- Codex runner implemented (Task T8).\n- Memory persistence available (Task T10).\n\n### Artifacts To Create/Modify\n- `src/cli/commands/agent.command.ts`\n- `tests/unit/cli/agent-wrapper.spec.ts`\n- Memory update utilities\n\n### Step-by-Step\n1. Resolve agent prompt path and memory file path based on the agent id.\n2. Build the composite prompt with system prompt, memory context, and user request.\n3. Execute the Codex CLI with the exact flags outlined in `runner-prompts/user-input.md`, including `--skip-git-repo-check`, `--sandbox danger-full-access`, and `--dangerously-bypass-approvals-and-sandbox`, while setting `CODEX_HOME` and `-C <workingDir>`.\n4. Stream results through the execution UI, record the spawned instance name (e.g., `frontend-dev-<timestamp>`), and append sanitized output to the appropriate memory file.\n\n### Verification\n- `npx vitest run tests/unit/cli/agent-wrapper.spec.ts` passes, asserting CLI arguments and memory updates.\n- Manual invocation shows composite prompt execution and memory persistence.\n\n### Rollback\nRemove the agent command and related utilities, restoring prior behaviour.\n",
      "subtasks": [
        {
          "id": "T21.1",
          "name": "Build composite prompt assembler",
          "details": "Read agent prompts and memory files, concatenating them with the runtime request.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T21.2",
          "name": "Execute Codex CLI with required flags",
          "details": "Wrap the Codex invocation with the documented `codex exec` options and working directory handling.",
          "blockedBy": [
            "T21.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T21.3",
          "name": "Persist agent memory output",
          "details": "Append sanitized output to `.codemachine/memory/.<agent>-memory.md` via the memory store.",
          "blockedBy": [
            "T21.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T21_TEST",
      "name": "Test Implement agent execution wrapper command",
      "phase": "Testing",
      "dependsOn": [
        "T21"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Implement agent execution wrapper command' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T21 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T21 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T21's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T21.\n\n### Rollback\nAddress deficiencies in Task T21 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T21.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T21_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T21.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T21_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T22",
      "name": "Orchestrate Master Mind 4-phase workflow",
      "phase": "Building",
      "dependsOn": [
        "T6_TEST",
        "T21_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "Master Mind reads `.codemachine/plan/tasks.json`, executes Planningâ†’Buildingâ†’Testingâ†’Runtime phases, evaluates outputs against acceptance criteria, triggers QA when needed, updates task status, and records progress logs.",
      "details": "### Purpose\nFulfill the documented end-to-end orchestration flow for automated project generation.\n\n### Preconditions\n- `/start` command implemented (Task T6).\n- Agent wrapper available (Task T21).\n\n### Artifacts To Create/Modify\n- `src/core/workflows/master-mind.ts`\n- `tests/integration/workflows/master-mind.spec.ts`\n- Logging hooks for phase transitions\n\n### Step-by-Step\n1. Load tasks from `.codemachine/plan/tasks.json` and process them sequentially unless flagged for parallel execution.\n2. For each phase, select the appropriate agent via the wrapper command and enforce acceptance criteria.\n3. Invoke QA agent when Master Mind accepts a task and ensure task state is persisted.\n4. Track time elapsed and phase metadata for the execution UI.\n\n### Verification\n- `npx vitest run tests/integration/workflows/master-mind.spec.ts` passes with mocked agents.\n- Manual dry-run shows phase transitions and task status updates matching expectations.\n\n### Rollback\nDisable Master Mind workflow wiring and remove integration tests.",
      "subtasks": [
        {
          "id": "T22.1",
          "name": "Load and sequence tasks",
          "details": "Implement logic that respects dependencies and `canWorkInParallel` flags from tasks.json.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T22.2",
          "name": "Execute phase-specific agents",
          "details": "Call the correct agent for Planning, Building, Testing, and Runtime while enforcing acceptance criteria.",
          "blockedBy": [
            "T22.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T22.3",
          "name": "Persist task progress",
          "details": "Update `.codemachine/plan/tasks.json` with status changes and write execution logs for analytics.",
          "blockedBy": [
            "T22.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T22_TEST",
      "name": "Test Orchestrate Master Mind 4-phase workflow",
      "phase": "Testing",
      "dependsOn": [
        "T22"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Orchestrate Master Mind 4-phase workflow' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T22 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T22 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T22's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T22.\n\n### Rollback\nAddress deficiencies in Task T22 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T22.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T22_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T22.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T22_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T23",
      "name": "Enable automatic recovery and completion agents",
      "phase": "Testing",
      "dependsOn": [
        "T22_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "When Master Mind stops, Project Summarizer writes `.codemachine/project-summary.md`; pending tasks trigger Retry agent to resume; completed plans call End agent to confirm success.",
      "details": "### Purpose\nAutomate post-run handling so project progress is never lost and users receive clear completion messaging.\n\n### Preconditions\n- Master Mind orchestration (Task T22).\n\n### Artifacts To Create/Modify\n- `src/agents/runtime/project-summarizer.ts`\n- `src/agents/runtime/retry.ts`\n- `src/agents/runtime/end.ts`\n- `tests/integration/workflows/recovery.spec.ts`\n\n### Step-by-Step\n1. Detect Master Mind termination and invoke Project Summarizer to build `project-summary.md`.\n2. If tasks remain, call Retry agent with context to resume orchestration.\n3. When all tasks are done, run End agent to emit the success banner.\n\n### Verification\n- `npx vitest run tests/integration/workflows/recovery.spec.ts` passes.\n- Manual interruption demonstrates summary generation and retry behavior per spec.\n\n### Rollback\nRemove recovery agents and associated wiring.",
      "subtasks": [
        {
          "id": "T23.1",
          "name": "Integrate Project Summarizer",
          "details": "Invoke summarizer automatically on Master Mind stop to create `project-summary.md`.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T23.2",
          "name": "Configure Retry agent",
          "details": "Restart Master Mind with the outstanding task context when work remains.",
          "blockedBy": [
            "T23.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T23.3",
          "name": "Finalize End agent flow",
          "details": "Emit completion messaging when all tasks mark as done.",
          "blockedBy": [
            "T23.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T23_TEST",
      "name": "Test Enable automatic recovery and completion agents",
      "phase": "Testing",
      "dependsOn": [
        "T23"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Enable automatic recovery and completion agents' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T23 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T23 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T23's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T23.\n\n### Rollback\nAddress deficiencies in Task T23 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T23.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T23_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T23.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T23_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T24",
      "name": "Document Gemini-inspired branding guidelines",
      "phase": "Planning",
      "dependsOn": [
        "T9_TEST",
        "T19_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "`docs/reference/branding.md` captures the blue gradient theme, ASCII banner usage, typography choices, and CLI layout rules derived from the Gemini inspiration, referencing palette tokens and controls.",
      "details": "### Purpose\nRecord visual conventions so future UI work remains consistent with the specification.\n\n### Preconditions\n- Presentation primitives complete (Task T9).\n- Main menu rendering available (Task T19).\n\n### Artifacts To Create/Modify\n- `docs/reference/branding.md`\n- Links from `.codemachine/plan.md` to the branding guide\n\n### Step-by-Step\n1. Summarize Gemini-inspired elements: blue gradient, typography, divider usage, execution screen layout.\n2. Describe how palette tokens map to CLI states (success, warning, error).\n3. Cross-reference typewriter guidelines and keyboard controls.\n4. Link the branding doc from `.codemachine/plan.md` for discoverability.\n\n### Verification\n- `rg 'Gemini UI' docs/reference/branding.md` returns a match.\n- `.codemachine/plan.md` includes a link to the branding reference.\n\n### Rollback\nRemove the branding document and associated references.",
      "subtasks": [
        {
          "id": "T24.1",
          "name": "Author branding reference",
          "details": "Draft the Markdown guide describing colors, gradients, and layout motifs.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T24.2",
          "name": "Link branding doc in plan",
          "details": "Update `.codemachine/plan.md` to list the branding reference alongside other planning assets.",
          "blockedBy": [
            "T24.1"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T24_TEST",
      "name": "Test Document Gemini-inspired branding guidelines",
      "phase": "Testing",
      "dependsOn": [
        "T24"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Document Gemini-inspired branding guidelines' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T24 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T24 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T24's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T24.\n\n### Rollback\nAddress deficiencies in Task T24 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T24.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T24_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T24.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T24_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T25",
      "name": "Map implementation priorities to delivery checkpoints",
      "phase": "Planning",
      "dependsOn": [
        "T1_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "`docs/architecture/implementation-roadmap.md` enumerates the Phase 1â€“4 checklists from the spec, links each item to owning tasks (T1â€“T24+), and marks completion status as work progresses.",
      "details": "### Purpose\nTranslate the specificationâ€™s implementation priorities into a trackable roadmap tied to tasks.\n\n### Preconditions\n- System boundaries documented (Task T1).\n\n### Artifacts To Create/Modify\n- `docs/architecture/implementation-roadmap.md`\n- `.codemachine/plan.md` reference\n\n### Step-by-Step\n1. Reproduce the Phase 1â€“4 bullet lists in Markdown.\n2. Annotate each bullet with the corresponding task id(s).\n3. Provide a status column or checkbox to monitor progress.\n4. Reference the roadmap from `.codemachine/plan.md`.\n\n### Verification\n- `rg 'Phase 1' docs/architecture/implementation-roadmap.md` shows the checklist.\n- Plan document links to the roadmap.\n\n### Rollback\nRemove the roadmap document and plan reference.",
      "subtasks": [
        {
          "id": "T25.1",
          "name": "Create roadmap document",
          "details": "Author the Markdown checklist matching the specificationâ€™s phases.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T25.2",
          "name": "Cross-link roadmap",
          "details": "Update `.codemachine/plan.md` to reference the roadmap for planning sessions.",
          "blockedBy": [
            "T25.1"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T25_TEST",
      "name": "Test Map implementation priorities to delivery checkpoints",
      "phase": "Testing",
      "dependsOn": [
        "T25"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Map implementation priorities to delivery checkpoints' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T25 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T25 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T25's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T25.\n\n### Rollback\nAddress deficiencies in Task T25 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T25.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T25_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T25.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T25_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T26",
      "name": "Publish next-steps execution checklist",
      "phase": "Planning",
      "dependsOn": [
        "T25_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "`docs/operations/next-steps.md` lists the seven next steps from the spec (TypeScript setup through iteration), assigns owners, and links to relevant scripts/tests.",
      "details": "### Purpose\nEnsure the documented next steps are tracked and actionable within the project.\n\n### Preconditions\n- Implementation roadmap available (Task T25).\n\n### Artifacts To Create/Modify\n- `docs/operations/next-steps.md`\n- Updates to `.codemachine/plan.md` or README linking the checklist\n\n### Step-by-Step\n1. Capture each bullet under \"Next Steps\" in `runner-prompts/user-input.md`.\n2. Assign responsible agents or teams and note any prerequisite tasks.\n3. Link to scripts or commands (e.g., CLI framework setup, Codex integration).\n4. Surface the checklist from planning materials.\n\n### Verification\n- `rg 'Set up TypeScript project structure' docs/operations/next-steps.md` returns a match.\n- README or plan references the checklist.\n\n### Rollback\nDelete the checklist and remove references.",
      "subtasks": [
        {
          "id": "T26.1",
          "name": "Draft next-steps checklist",
          "details": "Write the Markdown file with owners and links for each next step.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T26.2",
          "name": "Link checklist in docs",
          "details": "Reference the checklist from planning documentation or README.",
          "blockedBy": [
            "T26.1"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T26_TEST",
      "name": "Test Publish next-steps execution checklist",
      "phase": "Testing",
      "dependsOn": [
        "T26"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Publish next-steps execution checklist' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T26 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T26 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T26's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T26.\n\n### Rollback\nAddress deficiencies in Task T26 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T26.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T26_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T26.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T26_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T27",
      "name": "Automate agents-builder workspace seeding",
      "phase": "Building",
      "dependsOn": [
        "T17_TEST",
        "T22_TEST"
      ],
      "done": true,
      "acceptanceCriteria": "When `/start` runs, agents-builder generates agent-specific prompts in `.codemachine/agents/`, populates `.codemachine/plan/tasks.json`, and records instructions matching the spec before Master Mind takes over.",
      "details": "### Purpose\nComplete the project initialization flow described under Team Building in the specification.\n\n### Preconditions\n- Workspace bootstrap in place (Task T17).\n- Master Mind orchestration ready (Task T22).\n\n### Artifacts To Create/Modify\n- `src/agents/runtime/agents-builder.ts`\n- `tests/integration/workflows/agents-builder.spec.ts`\n- `.codemachine/agents/*.md` templates\n\n### Step-by-Step\n1. Invoke agents-builder during `/start` to read global prompts and produce project-specific agent files.\n2. Populate `.codemachine/plan/tasks.json` with tasks tailored to the user specification.\n3. Persist builder output so Master Mind can immediately continue execution.\n\n### Verification\n- `npx vitest run tests/integration/workflows/agents-builder.spec.ts` passes.\n- Manual `/start` run shows generated agent prompts and plan files aligned with the spec.\n\n### Rollback\nDisable agents-builder invocation and remove generated files.",
      "subtasks": [
        {
          "id": "T27.1",
          "name": "Integrate agents-builder",
          "details": "Trigger the builder during `/start` and feed it workspace metadata.",
          "blockedBy": [],
          "canWorkInParallel": false
        },
        {
          "id": "T27.2",
          "name": "Persist agent prompts and plan",
          "details": "Write agent prompt files and plan tasks to the project workspace.",
          "blockedBy": [
            "T27.1"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T27.3",
          "name": "Test builder workflow",
          "details": "Add integration coverage confirming generated files meet spec expectations.",
          "blockedBy": [
            "T27.2"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "T27_TEST",
      "name": "Test Automate agents-builder workspace seeding",
      "phase": "Testing",
      "dependsOn": [
        "T27"
      ],
      "done": true,
      "acceptanceCriteria": "Validation confirms 'Automate agents-builder workspace seeding' meets its acceptance criteria and all related requirements from runner-prompts/user-input.md.",
      "details": "\n### Purpose\nEnsure Task T27 satisfies every specification detail before downstream work begins.\n\n### Preconditions\n- Task T27 completed.\n\n### Validation Steps\n1. Execute the verification commands described in Task T27's acceptance criteria.\n2. Cross-check outputs against the relevant sections of `runner-prompts/user-input.md` (CLI workflow, UI design, automation, and documentation expectations).\n3. Record results in the appropriate memory file or documentation log so future agents have traceability.\n\n### Verification\n- Evidence of passing commands stored in CI logs or local notes.\n- Review confirms no unmet requirements remain for Task T27.\n\n### Rollback\nAddress deficiencies in Task T27 and re-run this validation checklist.\n",
      "subtasks": [
        {
          "id": "T27.T1",
          "name": "Run verification commands",
          "details": "Execute all automated and manual checks referenced in the parent task's acceptance criteria.",
          "blockedBy": [
            "T27_TEST"
          ],
          "canWorkInParallel": false
        },
        {
          "id": "T27.T2",
          "name": "Document validation results",
          "details": "Log outcomes in project memory/docs and confirm alignment with runner-prompts/user-input.md requirements.",
          "blockedBy": [
            "T27_TEST"
          ],
          "canWorkInParallel": true
        }
      ]
    },
    {
      "id": "RT1",
      "name": "Runtime Phase 1 â€” Launch & Session (real-time, human-like)",
      "phase": "Runtime",
      "done": true,
      "acceptanceCriteria": "Runs in real time with human-like interactions; begins from a clean start of `codemachine`; session opens and stays open; main screen renders; dynamic menu reflects auth state; project `.codemachine/` structure and `.codemachine/agents/agents-config.json` are created on run; no isolated task testing; no steps skipped.",
      "details": "Run the bot end-to-end in a live terminal session exactly like a human user. Always start from a fresh launch by executing `codemachine` and conduct the entire flow for this phase without injecting state or skipping any interaction. Validate pre-start setup, on-run project bootstrap, global config sync, auth-aware menu, help/version, and session stability against runner-prompts/user-input.md.",
      "subtasks": [
        {
          "id": "RT1.1",
          "name": "Fresh launch",
          "details": "Start from clean state and run `codemachine` ensuring session stays open."
        },
        {
          "id": "RT1.2",
          "name": "UI verification",
          "details": "Confirm banner, mode, and prompt match the spec one-to-one."
        },
        {
          "id": "RT1.3",
          "name": "Bootstrap structure",
          "details": "`.codemachine/` directories exist on run; `agents-config.json` mirrored from global agents.js."
        },
        {
          "id": "RT1.4",
          "name": "Global config sync",
          "details": "`~/.codemachine/codex/config.toml` overwritten with latest agent profiles."
        },
        {
          "id": "RT1.5",
          "name": "Auth-aware menu",
          "details": "Menu shows `/login` if auth missing or `/logout` if present; includes `/start`, `/templates`, `/version`, `/help`, `/mcp`."
        },
        {
          "id": "RT1.6",
          "name": "Help & version",
          "details": "Run `/help` and `/version` and confirm outputs."
        }
      ]
    },
    {
      "id": "RT2",
      "name": "Runtime Phase 2 â€” /start & Initialization (real-time, human-like)",
      "phase": "Runtime",
      "done": true,
      "acceptanceCriteria": "Executed from fresh launch with real-time, human-like operation; `/start` prompts for specifications; NO branch returns to menu; YES branch proceeds to team building; agent prompt files created; `.codemachine/plan/tasks.json` generated; streaming UI works; no isolated or skipped steps.",
      "details": "Initiate `/start` from a freshly launched session and drive all interactions like a real user. Do not test steps in isolation. Validate specs confirmation, first-time `codex login` when needed, agents-builder execution, agent prompt generation, plan creation, streaming UI and control hints, and idempotency on re-run.",
      "subtasks": [
        {
          "id": "RT2.1",
          "name": "Specifications confirmation",
          "details": "Verify confirmation prompt for `.codemachine/inputs/specifications.md` and context files."
        },
        {
          "id": "RT2.2",
          "name": "NO branch",
          "details": "Choose NO and confirm return to menu with session still open."
        },
        {
          "id": "RT2.3",
          "name": "YES branch & team building",
          "details": "Proceed, open Codex session, run agents-builder, and generate agent prompts."
        },
        {
          "id": "RT2.4",
          "name": "Plan generation",
          "details": "Confirm `.codemachine/plan/tasks.json` created/updated with tasks from spec/template."
        },
        {
          "id": "RT2.5",
          "name": "Auth first-time flow",
          "details": "If missing auth, run `codex login`, verify creation of config and auth files, then resume and continue."
        },
        {
          "id": "RT2.6",
          "name": "Streaming UI & controls",
          "details": "Typewriter effect visible; Ctrl+C (modify plan), Ctrl+E (expand logs)."
        },
        {
          "id": "RT2.7",
          "name": "Idempotency",
          "details": "Re-run `/start` and verify no duplicate files and safe updates."
        }
      ]
    },
    {
      "id": "RT3",
      "name": "Runtime Phase 3 â€” Orchestration, Streaming, Delivery (real-time, human-like)",
      "phase": "Runtime",
      "done": true,
      "acceptanceCriteria": "Run starts from clean launch; human-like, real-time session; Master Mind reads plan; agents executed via wrapper; composite prompts assembled; outputs stream; memory files updated; QA validates; Retry/End agents trigger; project-summary generated; graceful exit; no isolated testing; no steps skipped.",
      "details": "From a fresh `codemachine` launch, execute the entire orchestration flow as a human would: Master Mind reads plan, calls agents via the CLI wrapper, streams output, tracks instances, writes memory, evaluates acceptance criteria, invokes QA, handles recovery (summarizer/retry), and completes with End Agent and delivery checks. Do not skip runtime steps or run isolated checks.",
      "subtasks": [
        {
          "id": "RT3.1",
          "name": "Select and dispatch tasks",
          "details": "Master Mind selects next task from plan and calls `codemachine --agent <name> \"<task prompt>\"`."
        },
        {
          "id": "RT3.2",
          "name": "Composite prompts & exec flags",
          "details": "Confirm assembly [agent-prompt.md + memory.md + task], and flags `--profile`, `--skip-git-repo-check`, `--sandbox danger-full-access`, `--dangerously-bypass-approvals-and-sandbox`, `-C <workingDir>`."
        },
        {
          "id": "RT3.3",
          "name": "Streaming & UI updates",
          "details": "Typewriter after `User Request:` marker; task/phase/time display updates correctly."
        },
        {
          "id": "RT3.4",
          "name": "Instance tracking & states",
          "details": "Validate `<agent>-<timestamp>` IDs and state transitions runningâ†’completed/error/terminated."
        },
        {
          "id": "RT3.5",
          "name": "Memory writes",
          "details": "Sanitized outputs saved under `.codemachine/memory/*.md` for each agent."
        },
        {
          "id": "RT3.6",
          "name": "Acceptance and QA",
          "details": "Master Mind evaluates acceptance; QA agent tests; update task status in plan."
        },
        {
          "id": "RT3.7",
          "name": "Recovery & completion",
          "details": "If interrupted, summarizer then retry; on full completion, End Agent confirms and `project-summary.md` exists; exit cleanly."
        }
      ]
    }
  ]
}